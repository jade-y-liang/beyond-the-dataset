<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Jade Liang">
<meta name="dcterms.date" content="2024-12-02">

<title>Sample – myblog</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">myblog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Sample</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">homework</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Jade Liang </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">December 2, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p>In this post, I will show you how to develop and assess a fake news classifier using Keras.</p>
<section id="acquire-training-data" class="level1">
<h1>1. Acquire Training Data</h1>
<p>We will first import the data set for this project. Here is the <a href="https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset">source</a> of the data set. The following url contains the training data set.</p>
<div id="CKu4eiYrzP86" class="cell" data-outputid="03d9ee0f-3c93-44f6-e4e7-d2b7a676f074" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>train_url <span class="op">=</span> <span class="st">"https://github.com/PhilChodrow/PIC16b/blob/master/datasets/fake_news_train.csv?raw=true"</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>train_data <span class="op">=</span> pd.read_csv(train_url)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>train_data.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1">

  <div id="df-05e9e05c-4c28-4e43-b57f-070ab6fd4d0f" class="colab-df-container">
    <div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Unnamed: 0</th>
<th data-quarto-table-cell-role="th">title</th>
<th data-quarto-table-cell-role="th">text</th>
<th data-quarto-table-cell-role="th">fake</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>17366</td>
<td>Merkel: Strong result for Austria's FPO 'big c...</td>
<td>German Chancellor Angela Merkel said on Monday...</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>5634</td>
<td>Trump says Pence will lead voter fraud panel</td>
<td>WEST PALM BEACH, Fla.President Donald Trump sa...</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>17487</td>
<td>JUST IN: SUSPECTED LEAKER and “Close Confidant...</td>
<td>On December 5, 2017, Circa s Sara Carter warne...</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>12217</td>
<td>Thyssenkrupp has offered help to Argentina ove...</td>
<td>Germany s Thyssenkrupp, has offered assistance...</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>5535</td>
<td>Trump say appeals court decision on travel ban...</td>
<td>President Donald Trump on Thursday called the ...</td>
<td>0</td>
</tr>
</tbody>
</table>

</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-05e9e05c-4c28-4e43-b57f-070ab6fd4d0f')" title="Convert this dataframe to an interactive table." style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"></path>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-05e9e05c-4c28-4e43-b57f-070ab6fd4d0f button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-05e9e05c-4c28-4e43-b57f-070ab6fd4d0f');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


<div id="df-a726ba80-6f62-4208-b73a-a279bf53ab4b">
  <button class="colab-df-quickchart" onclick="quickchart('df-a726ba80-6f62-4208-b73a-a279bf53ab4b')" title="Suggest charts" style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 0 24 24" width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"></path>
    </g>
</svg>
  </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

  <script>
    async function quickchart(key) {
      const quickchartButtonEl =
        document.querySelector('#' + key + ' button');
      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
      quickchartButtonEl.classList.add('colab-df-spinner');
      try {
        const charts = await google.colab.kernel.invokeFunction(
            'suggestCharts', [key], {});
      } catch (error) {
        console.error('Error during call to suggestCharts:', error);
      }
      quickchartButtonEl.classList.remove('colab-df-spinner');
      quickchartButtonEl.classList.add('colab-df-quickchart-complete');
    }
    (() => {
      let quickchartButtonEl =
        document.querySelector('#df-a726ba80-6f62-4208-b73a-a279bf53ab4b button');
      quickchartButtonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';
    })();
  </script>
</div>

    </div>
  </div>
</div>
</div>
<p>Note that each row of the data corresponds to an article. The <code>title</code> column gives the title of the article, whereas the <code>text</code> column gives the full article text. The final column, <code>fake</code>, is <code>0</code> if the article is real news and <code>1</code> if the article is fake news.</p>
</section>
<section id="make-a-dataset" class="level1">
<h1>2. Make a Dataset</h1>
<p>Next, we will implement a function called <code>make_dataset</code> to clean our training data and prepare it for training. Here’s what the function looks like:</p>
<div id="c3keRP8gzLkb" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> keras</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras <span class="im">import</span> layers</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras <span class="im">import</span> ops</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.corpus <span class="im">import</span> stopwords</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> make_dataset(train_data):</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>  <span class="co">""" changes the text of training data to lowercase,</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="co">      removes stopwords from text and title, and returns</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="co">      a tf.data.Dataset with two inputs and one output """</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>  <span class="co"># converts text to lowercase</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>  train_data[<span class="st">"text"</span>] <span class="op">=</span> train_data[<span class="st">"text"</span>].<span class="bu">str</span>.lower()</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>  <span class="co"># removes stopwords from title and text</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>  stop <span class="op">=</span> stopwords.words(<span class="st">'english'</span>) <span class="co"># loading english stop words</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>  train_data[<span class="st">"title"</span>] <span class="op">=</span> train_data[<span class="st">"title"</span>].<span class="bu">apply</span>(</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>      <span class="kw">lambda</span> x: <span class="st">' '</span>.join([word <span class="cf">for</span> word <span class="kw">in</span> x.split() <span class="cf">if</span> word <span class="kw">not</span> <span class="kw">in</span> (stop)]))</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>  train_data[<span class="st">"text"</span>] <span class="op">=</span> train_data[<span class="st">"text"</span>].<span class="bu">apply</span>(</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>      <span class="kw">lambda</span> x: <span class="st">' '</span>.join([word <span class="cf">for</span> word <span class="kw">in</span> x.split() <span class="cf">if</span> word <span class="kw">not</span> <span class="kw">in</span> (stop)]))</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>  dataset <span class="op">=</span> tf.data.Dataset.from_tensor_slices((</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>      {<span class="st">"title"</span>: train_data[<span class="st">"title"</span>].values, <span class="co"># (title, text) as input</span></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>       <span class="st">"text"</span>: train_data[<span class="st">"text"</span>].values},</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>      train_data[<span class="st">"fake"</span>].values   <span class="co"># fake column as output</span></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>  ))</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>  <span class="co"># batching dataset (allows model to train on chunks rather than rows)</span></span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>  dataset <span class="op">=</span> dataset.batch(<span class="dv">100</span>)</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> dataset</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="Gpx21h5amETG" class="cell" data-outputid="89cf8bd3-1afc-4952-ee63-e286ddc0d4fe" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> make_dataset(train_data)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>dataset</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<pre><code>&lt;_BatchDataset element_spec=({'title': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'text': TensorSpec(shape=(None,), dtype=tf.string, name=None)}, TensorSpec(shape=(None,), dtype=tf.int64, name=None))&gt;</code></pre>
</div>
</div>
<p>Next, we will split 20% of our <code>dataset</code> to use for validation. Notice that we are using 45 batches for our validation data.</p>
<div id="J7jQP5u4sRZ-" class="cell" data-outputid="2ef50c91-e474-48d1-9081-d7408c3b379b" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> dataset.shuffle(buffer_size <span class="op">=</span> <span class="bu">len</span>(dataset),</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>                       reshuffle_each_iteration <span class="op">=</span> <span class="va">False</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>train_size <span class="op">=</span> <span class="bu">int</span>(<span class="fl">0.8</span><span class="op">*</span><span class="bu">len</span>(dataset))</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>val_size <span class="op">=</span> <span class="bu">int</span>(<span class="fl">0.2</span><span class="op">*</span><span class="bu">len</span>(dataset))</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>train <span class="op">=</span> dataset.take(train_size)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>val   <span class="op">=</span> dataset.skip(train_size).take(val_size)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(train), <span class="bu">len</span>(val)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>(180, 45)</code></pre>
</div>
</div>
<p>We’ll now determine the base rate for our dataset by examining the labels on the training set. As we can see, the base rate is roughly 53%, which is what one might expect.</p>
<div id="qD93bU0Vsziz" class="cell" data-outputid="a379d890-b49e-4737-a352-72e1071db7f2" data-execution_count="5">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_base_rate(train_data):</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Count the number of instances of each class (1 and 0)</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    class_counts <span class="op">=</span> train_data[<span class="st">"fake"</span>].value_counts()</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate the base rate by finding the max count divided by</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># total number of samples</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    base_rate <span class="op">=</span> class_counts.<span class="bu">max</span>() <span class="op">/</span> class_counts.<span class="bu">sum</span>()</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> base_rate</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate and print the base rate</span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>base_rate <span class="op">=</span> calculate_base_rate(train_data)</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Base Rate:"</span>, base_rate)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Base Rate: 0.522963160942581</code></pre>
</div>
</div>
<p>Finally, we will prepare a text vectorization layer for our tf model.</p>
<div id="I6WN52AKtfxu" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.layers <span class="im">import</span> TextVectorization</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> string</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="co">#preparing a text vectorization layer for tf model</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>size_vocabulary <span class="op">=</span> <span class="dv">2000</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> standardization(input_data):</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    lowercase <span class="op">=</span> tf.strings.lower(input_data)</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    no_punctuation <span class="op">=</span> tf.strings.regex_replace(lowercase,</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>                                  <span class="st">'[</span><span class="sc">%s</span><span class="st">]'</span> <span class="op">%</span> re.escape(string.punctuation),<span class="st">''</span>)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> no_punctuation</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>title_vectorize_layer <span class="op">=</span> TextVectorization(</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>    standardize<span class="op">=</span>standardization,</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>    max_tokens<span class="op">=</span>size_vocabulary, <span class="co"># only consider this many words</span></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>    output_mode<span class="op">=</span><span class="st">'int'</span>,</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>    output_sequence_length<span class="op">=</span><span class="dv">500</span>)</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>title_vectorize_layer.adapt(train.<span class="bu">map</span>(<span class="kw">lambda</span> x, y: x[<span class="st">"title"</span>]))</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>text_vectorize_layer <span class="op">=</span> TextVectorization(</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>    standardize<span class="op">=</span>standardization,</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>    max_tokens<span class="op">=</span>size_vocabulary, <span class="co"># only consider this many words</span></span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>    output_mode<span class="op">=</span><span class="st">'int'</span>,</span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>    output_sequence_length<span class="op">=</span><span class="dv">500</span>)</span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a>text_vectorize_layer.adapt(train.<span class="bu">map</span>(<span class="kw">lambda</span> x, y: x[<span class="st">"text"</span>]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="create-models" class="level2">
<h2 class="anchored" data-anchor-id="create-models">3. Create Models</h2>
<p>We will create three Keras model to offer a perspective the following question:</p>
<p>When detecting fake news, is it most effective to focus on only the title of the article, the full text of the article, or both?</p>
<p>For the first model, we will use <strong>only the article title</strong> as input.</p>
<div id="ulJ0MikyK0Rt" class="cell" data-outputid="e418de8f-1d0f-424d-daf0-b861888e39bb" data-execution_count="32">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.losses <span class="im">import</span> BinaryCrossentropy</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>train_data <span class="op">=</span> train.<span class="bu">map</span>(<span class="kw">lambda</span> x, y: x[<span class="st">"title"</span>])</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>title_vectorize_layer.adapt(train_data)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="co"># input layer</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>title_input <span class="op">=</span> keras.Input(shape<span class="op">=</span>(<span class="dv">1</span>,), dtype<span class="op">=</span><span class="st">"string"</span>, name<span class="op">=</span><span class="st">"title"</span>)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a><span class="co"># text processing layers</span></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>title_features <span class="op">=</span> title_vectorize_layer(title_input)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>title_features <span class="op">=</span> layers.Embedding(size_vocabulary, <span class="dv">3</span>, name<span class="op">=</span><span class="st">"embedding"</span>)(title_features)</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>title_features <span class="op">=</span> layers.Dropout(<span class="fl">0.2</span>)(title_features)</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>title_features <span class="op">=</span> layers.GlobalAveragePooling1D()(title_features)</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>title_features <span class="op">=</span> layers.Dropout(<span class="fl">0.2</span>)(title_features)</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>title_features <span class="op">=</span> layers.Dense(<span class="dv">32</span>, activation<span class="op">=</span><span class="st">'relu'</span>)(title_features)</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a><span class="co"># output layer</span></span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>output <span class="op">=</span> layers.Dense(<span class="dv">1</span>, activation<span class="op">=</span><span class="st">'sigmoid'</span>)(title_features)</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a><span class="co"># model compilation (need to do this before training)</span></span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>model1 <span class="op">=</span> keras.Model(inputs<span class="op">=</span>title_input, outputs<span class="op">=</span>output)</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>model1.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">'adam'</span>, loss<span class="op">=</span><span class="st">'binary_crossentropy'</span>,</span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a>                    metrics<span class="op">=</span>[<span class="st">'accuracy'</span>])</span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>model1.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold">Model: "functional_7"</span>
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃<span style="font-weight: bold"> Layer (type)                         </span>┃<span style="font-weight: bold"> Output Shape                </span>┃<span style="font-weight: bold">         Param # </span>┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ title (<span style="color: #0087ff; text-decoration-color: #0087ff">InputLayer</span>)                   │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">1</span>)                   │               <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ text_vectorization                   │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">500</span>)                 │               <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">TextVectorization</span>)                  │                             │                 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ embedding (<span style="color: #0087ff; text-decoration-color: #0087ff">Embedding</span>)                │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">500</span>, <span style="color: #00af00; text-decoration-color: #00af00">3</span>)              │           <span style="color: #00af00; text-decoration-color: #00af00">6,000</span> │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout_8 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)                  │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">500</span>, <span style="color: #00af00; text-decoration-color: #00af00">3</span>)              │               <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ global_average_pooling1d_12          │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">3</span>)                   │               <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">GlobalAveragePooling1D</span>)             │                             │                 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout_9 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)                  │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">3</span>)                   │               <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense_10 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                     │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">32</span>)                  │             <span style="color: #00af00; text-decoration-color: #00af00">128</span> │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense_11 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                     │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">1</span>)                   │              <span style="color: #00af00; text-decoration-color: #00af00">33</span> │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Total params: </span><span style="color: #00af00; text-decoration-color: #00af00">6,161</span> (24.07 KB)
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">6,161</span> (24.07 KB)
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Non-trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">0</span> (0.00 B)
</pre>
</div>
</div>
<div id="qcC63HszK2C4" class="cell" data-outputid="cfc6da88-69f7-4174-af80-1535a921f342" data-execution_count="33">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># to visualize the model</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras <span class="im">import</span> utils</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>utils.plot_model(model1, <span class="st">"output_filename.png"</span>,</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>                       show_shapes<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>                       show_layer_names<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="33">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-9-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Now we train our model.</p>
<div id="XWBLlYDOVrUo" class="cell" data-outputid="459782bc-82ac-4e5e-d206-073e9d7f08b4" data-execution_count="34">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># implement callback for early stopping to prevent overfitting</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>callback <span class="op">=</span> keras.callbacks.EarlyStopping(monitor<span class="op">=</span><span class="st">'val_loss'</span>, patience<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="co"># train model</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model1.fit(train,</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>                    validation_data<span class="op">=</span>val,</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>                    epochs <span class="op">=</span> <span class="dv">50</span>,</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>                    callbacks<span class="op">=</span>[callback],</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>                    verbose <span class="op">=</span> <span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 8s 34ms/step - accuracy: 0.5263 - loss: 0.6890 - val_accuracy: 0.8038 - val_loss: 0.6404
Epoch 2/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 9s 27ms/step - accuracy: 0.8175 - loss: 0.5799 - val_accuracy: 0.9451 - val_loss: 0.3571
Epoch 3/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 6s 28ms/step - accuracy: 0.9034 - loss: 0.3341 - val_accuracy: 0.9218 - val_loss: 0.2310
Epoch 4/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 23ms/step - accuracy: 0.9200 - loss: 0.2399 - val_accuracy: 0.9253 - val_loss: 0.1896
Epoch 5/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 20ms/step - accuracy: 0.9359 - loss: 0.1982 - val_accuracy: 0.9187 - val_loss: 0.1785
Epoch 6/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 8s 33ms/step - accuracy: 0.9346 - loss: 0.1861 - val_accuracy: 0.9178 - val_loss: 0.1721
Epoch 7/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 8s 23ms/step - accuracy: 0.9419 - loss: 0.1732 - val_accuracy: 0.9304 - val_loss: 0.1544
Epoch 8/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 20ms/step - accuracy: 0.9456 - loss: 0.1605 - val_accuracy: 0.9420 - val_loss: 0.1401
Epoch 9/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 20ms/step - accuracy: 0.9461 - loss: 0.1510 - val_accuracy: 0.9318 - val_loss: 0.1473
Epoch 10/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 6s 31ms/step - accuracy: 0.9489 - loss: 0.1432 - val_accuracy: 0.9484 - val_loss: 0.1268
Epoch 11/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 22ms/step - accuracy: 0.9529 - loss: 0.1387 - val_accuracy: 0.9518 - val_loss: 0.1197
Epoch 12/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 20ms/step - accuracy: 0.9566 - loss: 0.1315 - val_accuracy: 0.9736 - val_loss: 0.1140
Epoch 13/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 7s 32ms/step - accuracy: 0.9585 - loss: 0.1236 - val_accuracy: 0.9498 - val_loss: 0.1200
Epoch 14/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 20ms/step - accuracy: 0.9564 - loss: 0.1222 - val_accuracy: 0.9529 - val_loss: 0.1128
Epoch 15/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 8s 34ms/step - accuracy: 0.9593 - loss: 0.1132 - val_accuracy: 0.9458 - val_loss: 0.1232
Epoch 16/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 21ms/step - accuracy: 0.9578 - loss: 0.1207 - val_accuracy: 0.9504 - val_loss: 0.1169
Epoch 17/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 20ms/step - accuracy: 0.9614 - loss: 0.1091 - val_accuracy: 0.9544 - val_loss: 0.1068
Epoch 18/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 6s 28ms/step - accuracy: 0.9612 - loss: 0.1090 - val_accuracy: 0.9549 - val_loss: 0.1049
Epoch 19/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 21ms/step - accuracy: 0.9593 - loss: 0.1082 - val_accuracy: 0.9564 - val_loss: 0.1032
Epoch 20/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 20ms/step - accuracy: 0.9630 - loss: 0.1005 - val_accuracy: 0.9551 - val_loss: 0.1044
Epoch 21/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 7s 32ms/step - accuracy: 0.9616 - loss: 0.1012 - val_accuracy: 0.9540 - val_loss: 0.1082
Epoch 22/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 21ms/step - accuracy: 0.9661 - loss: 0.0966 - val_accuracy: 0.9549 - val_loss: 0.1027
Epoch 23/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 23ms/step - accuracy: 0.9638 - loss: 0.0972 - val_accuracy: 0.9544 - val_loss: 0.1038
Epoch 24/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 25ms/step - accuracy: 0.9652 - loss: 0.0931 - val_accuracy: 0.9780 - val_loss: 0.0962
Epoch 25/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 6s 28ms/step - accuracy: 0.9687 - loss: 0.0883 - val_accuracy: 0.9776 - val_loss: 0.0956
Epoch 26/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 11s 32ms/step - accuracy: 0.9664 - loss: 0.0908 - val_accuracy: 0.9553 - val_loss: 0.1004
Epoch 27/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 29ms/step - accuracy: 0.9662 - loss: 0.0882 - val_accuracy: 0.9769 - val_loss: 0.0926
Epoch 28/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 9s 21ms/step - accuracy: 0.9686 - loss: 0.0857 - val_accuracy: 0.9776 - val_loss: 0.0880
Epoch 29/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 27ms/step - accuracy: 0.9705 - loss: 0.0806 - val_accuracy: 0.9782 - val_loss: 0.0901
Epoch 30/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 21ms/step - accuracy: 0.9715 - loss: 0.0789 - val_accuracy: 0.9789 - val_loss: 0.0889
Epoch 31/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 20ms/step - accuracy: 0.9700 - loss: 0.0803 - val_accuracy: 0.9778 - val_loss: 0.0918
Epoch 32/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 23ms/step - accuracy: 0.9745 - loss: 0.0742 - val_accuracy: 0.9784 - val_loss: 0.0868
Epoch 33/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 21ms/step - accuracy: 0.9715 - loss: 0.0752 - val_accuracy: 0.9756 - val_loss: 0.0914
Epoch 34/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 20ms/step - accuracy: 0.9698 - loss: 0.0771 - val_accuracy: 0.9780 - val_loss: 0.0927
Epoch 35/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 7s 31ms/step - accuracy: 0.9681 - loss: 0.0814 - val_accuracy: 0.9567 - val_loss: 0.0978
Epoch 36/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 20ms/step - accuracy: 0.9712 - loss: 0.0743 - val_accuracy: 0.9784 - val_loss: 0.0915
Epoch 37/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 20ms/step - accuracy: 0.9684 - loss: 0.0834 - val_accuracy: 0.9780 - val_loss: 0.0843
Epoch 38/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 29ms/step - accuracy: 0.9756 - loss: 0.0672 - val_accuracy: 0.9769 - val_loss: 0.0861
Epoch 39/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 9s 20ms/step - accuracy: 0.9720 - loss: 0.0735 - val_accuracy: 0.9767 - val_loss: 0.0893
Epoch 40/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 29ms/step - accuracy: 0.9740 - loss: 0.0682 - val_accuracy: 0.9778 - val_loss: 0.0846
Epoch 41/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 9s 20ms/step - accuracy: 0.9758 - loss: 0.0667 - val_accuracy: 0.9767 - val_loss: 0.0945
Epoch 42/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 7s 29ms/step - accuracy: 0.9747 - loss: 0.0656 - val_accuracy: 0.9780 - val_loss: 0.0913</code></pre>
</div>
</div>
<div id="rgU_7CG8aID7" class="cell" data-outputid="1535fb4b-0056-43e3-c1d5-0a20bc88467a" data-execution_count="35">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pyplot <span class="im">as</span> plt</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">"accuracy"</span>],label<span class="op">=</span><span class="st">'training'</span>)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">"val_accuracy"</span>],label<span class="op">=</span><span class="st">'validation'</span>)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>plt.legend()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-11-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="yNeGsx4Zbvdq" class="cell" data-outputid="eb5213f9-0632-4fe1-a4e6-c367a544fd2a" data-execution_count="36">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">"loss"</span>],label<span class="op">=</span><span class="st">'training'</span>)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">"val_loss"</span>],label<span class="op">=</span><span class="st">'validation'</span>)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>plt.legend()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-12-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>It appears that <code>model1</code>’s accuracy ranges between 96% and 97.5%.</p>
<p>For the second model, we will use <strong>only the article text</strong> as input. Once again, we’ll compile and then train the model.</p>
<div id="0mTkJfTSVpk8" class="cell" data-outputid="31f5e73b-f92b-43eb-e582-59cbb347b353" data-execution_count="37">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>train_texts <span class="op">=</span> train.<span class="bu">map</span>(<span class="kw">lambda</span> x, y: x[<span class="st">'text'</span>])</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>text_vectorize_layer.adapt(train_texts)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="co"># input Layer</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>text_input <span class="op">=</span> keras.Input(shape<span class="op">=</span>(<span class="dv">1</span>,), dtype<span class="op">=</span><span class="st">"string"</span>, name<span class="op">=</span><span class="st">"text"</span>)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="co"># text processing layers</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>text_features <span class="op">=</span> text_vectorize_layer(text_input)</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>text_features <span class="op">=</span> layers.Embedding(size_vocabulary, <span class="dv">3</span>, name<span class="op">=</span><span class="st">"embedding"</span>)(text_features)</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>text_features <span class="op">=</span> layers.Dropout(<span class="fl">0.2</span>)(text_features)</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>text_features <span class="op">=</span> layers.GlobalAveragePooling1D()(text_features)</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>text_features <span class="op">=</span> layers.Dropout(<span class="fl">0.2</span>)(text_features)</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>text_features <span class="op">=</span> layers.Dense(<span class="dv">32</span>, activation<span class="op">=</span><span class="st">'relu'</span>)(text_features)</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a><span class="co"># output layer</span></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>output <span class="op">=</span> layers.Dense(<span class="dv">1</span>, activation<span class="op">=</span><span class="st">'sigmoid'</span>)(text_features)</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Model Compilation</span></span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>model2 <span class="op">=</span> keras.Model(inputs<span class="op">=</span>text_input, outputs<span class="op">=</span>output)</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>model2.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">'adam'</span>, loss<span class="op">=</span><span class="st">'binary_crossentropy'</span>,</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>                    metrics<span class="op">=</span>[<span class="st">'accuracy'</span>])</span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>model2.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold">Model: "functional_8"</span>
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃<span style="font-weight: bold"> Layer (type)                         </span>┃<span style="font-weight: bold"> Output Shape                </span>┃<span style="font-weight: bold">         Param # </span>┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ text (<span style="color: #0087ff; text-decoration-color: #0087ff">InputLayer</span>)                    │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">1</span>)                   │               <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ text_vectorization_1                 │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">500</span>)                 │               <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">TextVectorization</span>)                  │                             │                 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ embedding (<span style="color: #0087ff; text-decoration-color: #0087ff">Embedding</span>)                │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">500</span>, <span style="color: #00af00; text-decoration-color: #00af00">3</span>)              │           <span style="color: #00af00; text-decoration-color: #00af00">6,000</span> │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout_10 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)                 │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">500</span>, <span style="color: #00af00; text-decoration-color: #00af00">3</span>)              │               <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ global_average_pooling1d_13          │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">3</span>)                   │               <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">GlobalAveragePooling1D</span>)             │                             │                 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout_11 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)                 │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">3</span>)                   │               <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense_12 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                     │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">32</span>)                  │             <span style="color: #00af00; text-decoration-color: #00af00">128</span> │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense_13 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                     │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">1</span>)                   │              <span style="color: #00af00; text-decoration-color: #00af00">33</span> │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Total params: </span><span style="color: #00af00; text-decoration-color: #00af00">6,161</span> (24.07 KB)
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">6,161</span> (24.07 KB)
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Non-trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">0</span> (0.00 B)
</pre>
</div>
</div>
<div id="NOP0AbhOK4FG" class="cell" data-outputid="39ae99bc-b8cd-4a1e-882e-3e64bc3cd035" data-execution_count="38">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># to visualize the model</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>utils.plot_model(model2, <span class="st">"output_filename.png"</span>,</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>                       show_shapes<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>                       show_layer_names<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="38">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-14-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="TOkib6BQXCHr" class="cell" data-outputid="d8b0aa23-b5aa-47e5-9c4d-280ff8944898" data-execution_count="39">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># implement callback for early stopping to prevent overfitting</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>callback <span class="op">=</span> keras.callbacks.EarlyStopping(monitor<span class="op">=</span><span class="st">'val_loss'</span>, patience<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="co"># train model</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model2.fit(train,</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>                    validation_data<span class="op">=</span>val,</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>                    epochs <span class="op">=</span> <span class="dv">50</span>,</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>                    callbacks<span class="op">=</span>[callback],</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>                    verbose <span class="op">=</span> <span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 6s 21ms/step - accuracy: 0.5335 - loss: 0.6873 - val_accuracy: 0.8627 - val_loss: 0.6162
Epoch 2/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 9s 42ms/step - accuracy: 0.8523 - loss: 0.5490 - val_accuracy: 0.9489 - val_loss: 0.3287
Epoch 3/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 24ms/step - accuracy: 0.9127 - loss: 0.3132 - val_accuracy: 0.9229 - val_loss: 0.2216
Epoch 4/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 20ms/step - accuracy: 0.9291 - loss: 0.2258 - val_accuracy: 0.9189 - val_loss: 0.1876
Epoch 5/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 6s 26ms/step - accuracy: 0.9337 - loss: 0.1943 - val_accuracy: 0.9260 - val_loss: 0.1683
Epoch 6/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 20ms/step - accuracy: 0.9443 - loss: 0.1668 - val_accuracy: 0.9358 - val_loss: 0.1487
Epoch 7/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 6s 23ms/step - accuracy: 0.9461 - loss: 0.1542 - val_accuracy: 0.9356 - val_loss: 0.1424
Epoch 8/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 21ms/step - accuracy: 0.9473 - loss: 0.1461 - val_accuracy: 0.9447 - val_loss: 0.1310
Epoch 9/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 20ms/step - accuracy: 0.9509 - loss: 0.1354 - val_accuracy: 0.9478 - val_loss: 0.1252
Epoch 10/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 6s 27ms/step - accuracy: 0.9534 - loss: 0.1321 - val_accuracy: 0.9371 - val_loss: 0.1382
Epoch 11/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 20ms/step - accuracy: 0.9532 - loss: 0.1277 - val_accuracy: 0.9498 - val_loss: 0.1184
Epoch 12/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 20ms/step - accuracy: 0.9564 - loss: 0.1149 - val_accuracy: 0.9513 - val_loss: 0.1149
Epoch 13/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 23ms/step - accuracy: 0.9591 - loss: 0.1120 - val_accuracy: 0.9609 - val_loss: 0.1018
Epoch 14/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 21ms/step - accuracy: 0.9618 - loss: 0.1044 - val_accuracy: 0.9542 - val_loss: 0.1078
Epoch 15/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 20ms/step - accuracy: 0.9639 - loss: 0.1021 - val_accuracy: 0.9529 - val_loss: 0.1085
Epoch 16/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 26ms/step - accuracy: 0.9631 - loss: 0.0975 - val_accuracy: 0.9609 - val_loss: 0.0968
Epoch 17/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 21ms/step - accuracy: 0.9620 - loss: 0.0958 - val_accuracy: 0.9458 - val_loss: 0.1157
Epoch 18/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 20ms/step - accuracy: 0.9605 - loss: 0.1071 - val_accuracy: 0.9542 - val_loss: 0.1060
Epoch 19/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 6s 27ms/step - accuracy: 0.9673 - loss: 0.0880 - val_accuracy: 0.9533 - val_loss: 0.1069
Epoch 20/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 20ms/step - accuracy: 0.9646 - loss: 0.0891 - val_accuracy: 0.9598 - val_loss: 0.0926
Epoch 21/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 20ms/step - accuracy: 0.9667 - loss: 0.0844 - val_accuracy: 0.9580 - val_loss: 0.0994
Epoch 22/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 7s 29ms/step - accuracy: 0.9658 - loss: 0.0888 - val_accuracy: 0.9602 - val_loss: 0.0916
Epoch 23/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 9s 20ms/step - accuracy: 0.9685 - loss: 0.0788 - val_accuracy: 0.9600 - val_loss: 0.0923
Epoch 24/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 6s 25ms/step - accuracy: 0.9702 - loss: 0.0755 - val_accuracy: 0.9633 - val_loss: 0.0896
Epoch 25/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 20ms/step - accuracy: 0.9684 - loss: 0.0788 - val_accuracy: 0.9531 - val_loss: 0.1074
Epoch 26/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 6s 26ms/step - accuracy: 0.9712 - loss: 0.0748 - val_accuracy: 0.9593 - val_loss: 0.0921
Epoch 27/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 20ms/step - accuracy: 0.9726 - loss: 0.0703 - val_accuracy: 0.9607 - val_loss: 0.0903
Epoch 28/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 20ms/step - accuracy: 0.9743 - loss: 0.0654 - val_accuracy: 0.9596 - val_loss: 0.0916
Epoch 29/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 28ms/step - accuracy: 0.9755 - loss: 0.0656 - val_accuracy: 0.9482 - val_loss: 0.1184</code></pre>
</div>
</div>
<div id="eZK-bA-PaZu6" class="cell" data-outputid="9c2bcf5e-2ed6-4a51-d000-93be828c9077" data-execution_count="40">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">"accuracy"</span>],label<span class="op">=</span><span class="st">'training'</span>)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">"val_accuracy"</span>],label<span class="op">=</span><span class="st">'validation'</span>)</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>plt.legend()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-16-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="CoOKXp3ed7Jj" class="cell" data-outputid="d3dd71ea-bad2-4f5a-84ee-43d0910f8c16" data-execution_count="41">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">"loss"</span>],label<span class="op">=</span><span class="st">'training'</span>)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">"val_loss"</span>],label<span class="op">=</span><span class="st">'validation'</span>)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>plt.legend()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-17-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>It appears that <code>model2</code>’s accuracy ranges between 96.5% and 97.5%, which is a slight improvement compared to <code>model1</code>.</p>
<p>For the third model, we will use <strong>both the article title and the article text</strong> as input.</p>
<div id="SwgGcLmFahTb" class="cell" data-outputid="40e5a3cf-3065-466a-e406-eba9eb2169d7" data-execution_count="44">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.layers <span class="im">import</span> TextVectorization, Embedding, Dropout, GlobalAveragePooling1D, Dense, Input, concatenate</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>train_data <span class="op">=</span> train.<span class="bu">map</span>(<span class="kw">lambda</span> x, y: (x[<span class="st">"title"</span>], x[<span class="st">"text"</span>]))</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>train_titles, train_texts <span class="op">=</span> <span class="bu">zip</span>(<span class="op">*</span>train_data)</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>shared_embedding <span class="op">=</span> Embedding(size_vocabulary, <span class="dv">3</span>, name <span class="op">=</span> <span class="st">"embedding"</span>)</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>title_input <span class="op">=</span> Input(shape<span class="op">=</span>(<span class="dv">1</span>,), dtype<span class="op">=</span>tf.string, name<span class="op">=</span><span class="st">"title"</span>)</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>title_vectorized <span class="op">=</span> title_vectorize_layer(title_input)</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>title_embedded <span class="op">=</span> shared_embedding(title_vectorized)</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>title_processed <span class="op">=</span> GlobalAveragePooling1D()(title_embedded)</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>text_input <span class="op">=</span> Input(shape<span class="op">=</span>(<span class="dv">1</span>,), dtype<span class="op">=</span>tf.string, name<span class="op">=</span><span class="st">"text"</span>)</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>text_vectorized <span class="op">=</span> text_vectorize_layer(text_input)</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>text_embedded <span class="op">=</span> shared_embedding(text_vectorized)</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>text_processed <span class="op">=</span> GlobalAveragePooling1D()(text_embedded)</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>combined_features <span class="op">=</span> concatenate([title_processed, text_processed])</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>output <span class="op">=</span> Dense(<span class="dv">1</span>, activation<span class="op">=</span><span class="st">'sigmoid'</span>)(combined_features)</span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a>model3 <span class="op">=</span> keras.Model(inputs<span class="op">=</span>[title_input, text_input], outputs<span class="op">=</span>output)</span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a>model3.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">'adam'</span>, loss<span class="op">=</span><span class="st">'binary_crossentropy'</span>,</span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a>                    metrics<span class="op">=</span>[<span class="st">'accuracy'</span>])</span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a>model3.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold">Model: "functional_11"</span>
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓
┃<span style="font-weight: bold"> Layer (type)              </span>┃<span style="font-weight: bold"> Output Shape           </span>┃<span style="font-weight: bold">        Param # </span>┃<span style="font-weight: bold"> Connected to           </span>┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩
│ title (<span style="color: #0087ff; text-decoration-color: #0087ff">InputLayer</span>)        │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">1</span>)              │              <span style="color: #00af00; text-decoration-color: #00af00">0</span> │ -                      │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ text (<span style="color: #0087ff; text-decoration-color: #0087ff">InputLayer</span>)         │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">1</span>)              │              <span style="color: #00af00; text-decoration-color: #00af00">0</span> │ -                      │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ text_vectorization        │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">500</span>)            │              <span style="color: #00af00; text-decoration-color: #00af00">0</span> │ title[<span style="color: #00af00; text-decoration-color: #00af00">0</span>][<span style="color: #00af00; text-decoration-color: #00af00">0</span>]            │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">TextVectorization</span>)       │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ text_vectorization_1      │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">500</span>)            │              <span style="color: #00af00; text-decoration-color: #00af00">0</span> │ text[<span style="color: #00af00; text-decoration-color: #00af00">0</span>][<span style="color: #00af00; text-decoration-color: #00af00">0</span>]             │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">TextVectorization</span>)       │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ embedding (<span style="color: #0087ff; text-decoration-color: #0087ff">Embedding</span>)     │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">500</span>, <span style="color: #00af00; text-decoration-color: #00af00">3</span>)         │          <span style="color: #00af00; text-decoration-color: #00af00">6,000</span> │ text_vectorization[<span style="color: #00af00; text-decoration-color: #00af00">7</span>]… │
│                           │                        │                │ text_vectorization_1[<span style="color: #00af00; text-decoration-color: #00af00">…</span> │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ global_average_pooling1d… │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">3</span>)              │              <span style="color: #00af00; text-decoration-color: #00af00">0</span> │ embedding[<span style="color: #00af00; text-decoration-color: #00af00">0</span>][<span style="color: #00af00; text-decoration-color: #00af00">0</span>]        │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">GlobalAveragePooling1D</span>)  │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ global_average_pooling1d… │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">3</span>)              │              <span style="color: #00af00; text-decoration-color: #00af00">0</span> │ embedding[<span style="color: #00af00; text-decoration-color: #00af00">1</span>][<span style="color: #00af00; text-decoration-color: #00af00">0</span>]        │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">GlobalAveragePooling1D</span>)  │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ concatenate_4             │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">6</span>)              │              <span style="color: #00af00; text-decoration-color: #00af00">0</span> │ global_average_poolin… │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">Concatenate</span>)             │                        │                │ global_average_poolin… │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ dense_16 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)          │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">1</span>)              │              <span style="color: #00af00; text-decoration-color: #00af00">7</span> │ concatenate_4[<span style="color: #00af00; text-decoration-color: #00af00">0</span>][<span style="color: #00af00; text-decoration-color: #00af00">0</span>]    │
└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Total params: </span><span style="color: #00af00; text-decoration-color: #00af00">6,007</span> (23.46 KB)
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">6,007</span> (23.46 KB)
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Non-trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">0</span> (0.00 B)
</pre>
</div>
</div>
<div id="SO8LLX_gI5Ec" class="cell" data-outputid="f9fe998b-cf05-4932-a9ce-3b9d2c2349bb" data-execution_count="46">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>utils.plot_model(model3, <span class="st">"output_filename.png"</span>,</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>                       show_shapes<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>                       show_layer_names<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="46">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-19-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="_JjDgDwcgxMa" class="cell" data-outputid="fb0aa5e5-66c2-491a-84aa-b7926c47df7c" data-execution_count="45">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># implement callback for early stopping to prevent overfitting</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>callback <span class="op">=</span> keras.callbacks.EarlyStopping(monitor<span class="op">=</span><span class="st">'val_loss'</span>, patience<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="co"># train model</span></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model3.fit(train,</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>                    validation_data<span class="op">=</span>val,</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>                    epochs <span class="op">=</span> <span class="dv">50</span>,</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>                    callbacks<span class="op">=</span>[callback],</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>                    verbose <span class="op">=</span> <span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 7s 30ms/step - accuracy: 0.5798 - loss: 0.6851 - val_accuracy: 0.6607 - val_loss: 0.6560
Epoch 2/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 26ms/step - accuracy: 0.6959 - loss: 0.6448 - val_accuracy: 0.7358 - val_loss: 0.6053
Epoch 3/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 20ms/step - accuracy: 0.7639 - loss: 0.5922 - val_accuracy: 0.8273 - val_loss: 0.5465
Epoch 4/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 6s 27ms/step - accuracy: 0.8506 - loss: 0.5326 - val_accuracy: 0.9038 - val_loss: 0.4869
Epoch 5/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 26ms/step - accuracy: 0.9067 - loss: 0.4742 - val_accuracy: 0.9291 - val_loss: 0.4338
Epoch 6/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 6s 28ms/step - accuracy: 0.9252 - loss: 0.4234 - val_accuracy: 0.9378 - val_loss: 0.3895
Epoch 7/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 9s 22ms/step - accuracy: 0.9342 - loss: 0.3814 - val_accuracy: 0.9424 - val_loss: 0.3534
Epoch 8/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 6s 36ms/step - accuracy: 0.9386 - loss: 0.3473 - val_accuracy: 0.9447 - val_loss: 0.3241
Epoch 9/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 25ms/step - accuracy: 0.9416 - loss: 0.3195 - val_accuracy: 0.9464 - val_loss: 0.3000
Epoch 10/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 26ms/step - accuracy: 0.9448 - loss: 0.2966 - val_accuracy: 0.9473 - val_loss: 0.2800
Epoch 11/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 30ms/step - accuracy: 0.9460 - loss: 0.2776 - val_accuracy: 0.9496 - val_loss: 0.2631
Epoch 12/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 9s 22ms/step - accuracy: 0.9478 - loss: 0.2614 - val_accuracy: 0.9518 - val_loss: 0.2488
Epoch 13/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 6s 30ms/step - accuracy: 0.9500 - loss: 0.2476 - val_accuracy: 0.9527 - val_loss: 0.2364
Epoch 14/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 20ms/step - accuracy: 0.9514 - loss: 0.2357 - val_accuracy: 0.9556 - val_loss: 0.2257
Epoch 15/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 20ms/step - accuracy: 0.9527 - loss: 0.2252 - val_accuracy: 0.9558 - val_loss: 0.2162
Epoch 16/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 29ms/step - accuracy: 0.9541 - loss: 0.2159 - val_accuracy: 0.9556 - val_loss: 0.2079
Epoch 17/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 9s 20ms/step - accuracy: 0.9552 - loss: 0.2077 - val_accuracy: 0.9564 - val_loss: 0.2004
Epoch 18/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 6s 25ms/step - accuracy: 0.9564 - loss: 0.2002 - val_accuracy: 0.9576 - val_loss: 0.1937
Epoch 19/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 20ms/step - accuracy: 0.9573 - loss: 0.1935 - val_accuracy: 0.9589 - val_loss: 0.1876
Epoch 20/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 25ms/step - accuracy: 0.9583 - loss: 0.1874 - val_accuracy: 0.9602 - val_loss: 0.1821
Epoch 21/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 24ms/step - accuracy: 0.9598 - loss: 0.1818 - val_accuracy: 0.9618 - val_loss: 0.1771
Epoch 22/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 20ms/step - accuracy: 0.9605 - loss: 0.1767 - val_accuracy: 0.9627 - val_loss: 0.1725
Epoch 23/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 25ms/step - accuracy: 0.9615 - loss: 0.1719 - val_accuracy: 0.9636 - val_loss: 0.1683
Epoch 24/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 22ms/step - accuracy: 0.9618 - loss: 0.1675 - val_accuracy: 0.9638 - val_loss: 0.1644
Epoch 25/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 20ms/step - accuracy: 0.9626 - loss: 0.1634 - val_accuracy: 0.9642 - val_loss: 0.1607
Epoch 26/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 7s 30ms/step - accuracy: 0.9631 - loss: 0.1596 - val_accuracy: 0.9649 - val_loss: 0.1574
Epoch 27/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 9s 20ms/step - accuracy: 0.9638 - loss: 0.1560 - val_accuracy: 0.9651 - val_loss: 0.1542
Epoch 28/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 7s 30ms/step - accuracy: 0.9641 - loss: 0.1526 - val_accuracy: 0.9667 - val_loss: 0.1513
Epoch 29/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 20ms/step - accuracy: 0.9655 - loss: 0.1495 - val_accuracy: 0.9669 - val_loss: 0.1485
Epoch 30/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 6s 25ms/step - accuracy: 0.9658 - loss: 0.1464 - val_accuracy: 0.9680 - val_loss: 0.1460
Epoch 31/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 21ms/step - accuracy: 0.9665 - loss: 0.1436 - val_accuracy: 0.9682 - val_loss: 0.1435
Epoch 32/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 20ms/step - accuracy: 0.9668 - loss: 0.1409 - val_accuracy: 0.9684 - val_loss: 0.1412
Epoch 33/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 7s 31ms/step - accuracy: 0.9677 - loss: 0.1383 - val_accuracy: 0.9693 - val_loss: 0.1391
Epoch 34/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 20ms/step - accuracy: 0.9681 - loss: 0.1359 - val_accuracy: 0.9696 - val_loss: 0.1370
Epoch 35/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 20ms/step - accuracy: 0.9682 - loss: 0.1335 - val_accuracy: 0.9702 - val_loss: 0.1351
Epoch 36/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 6s 25ms/step - accuracy: 0.9689 - loss: 0.1313 - val_accuracy: 0.9700 - val_loss: 0.1332
Epoch 37/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 20ms/step - accuracy: 0.9690 - loss: 0.1291 - val_accuracy: 0.9702 - val_loss: 0.1315
Epoch 38/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 20ms/step - accuracy: 0.9694 - loss: 0.1271 - val_accuracy: 0.9711 - val_loss: 0.1298
Epoch 39/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 8s 38ms/step - accuracy: 0.9695 - loss: 0.1251 - val_accuracy: 0.9713 - val_loss: 0.1282
Epoch 40/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 8s 27ms/step - accuracy: 0.9697 - loss: 0.1232 - val_accuracy: 0.9718 - val_loss: 0.1267
Epoch 41/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 22ms/step - accuracy: 0.9700 - loss: 0.1213 - val_accuracy: 0.9727 - val_loss: 0.1252
Epoch 42/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 20ms/step - accuracy: 0.9701 - loss: 0.1196 - val_accuracy: 0.9729 - val_loss: 0.1238
Epoch 43/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 7s 31ms/step - accuracy: 0.9707 - loss: 0.1178 - val_accuracy: 0.9727 - val_loss: 0.1224
Epoch 44/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 20ms/step - accuracy: 0.9712 - loss: 0.1162 - val_accuracy: 0.9729 - val_loss: 0.1211
Epoch 45/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 21ms/step - accuracy: 0.9718 - loss: 0.1146 - val_accuracy: 0.9729 - val_loss: 0.1199
Epoch 46/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 29ms/step - accuracy: 0.9721 - loss: 0.1130 - val_accuracy: 0.9733 - val_loss: 0.1187
Epoch 47/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 9s 21ms/step - accuracy: 0.9723 - loss: 0.1115 - val_accuracy: 0.9731 - val_loss: 0.1176
Epoch 48/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 8s 35ms/step - accuracy: 0.9725 - loss: 0.1100 - val_accuracy: 0.9736 - val_loss: 0.1164
Epoch 49/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 8s 24ms/step - accuracy: 0.9729 - loss: 0.1086 - val_accuracy: 0.9736 - val_loss: 0.1154
Epoch 50/50
180/180 ━━━━━━━━━━━━━━━━━━━━ 6s 34ms/step - accuracy: 0.9731 - loss: 0.1072 - val_accuracy: 0.9738 - val_loss: 0.1143</code></pre>
</div>
</div>
<div id="wtYO6gMxjuxj" class="cell" data-outputid="1c9a65ca-be0a-43d3-e80b-58a1ff34a96c" data-execution_count="47">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">"accuracy"</span>],label<span class="op">=</span><span class="st">'training'</span>)</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">"val_accuracy"</span>],label<span class="op">=</span><span class="st">'validation'</span>)</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>plt.legend()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-21-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="a_Q4FFE1j87z" class="cell" data-outputid="5b52efd8-1cf6-4e33-b0cc-3b775e2ba299" data-execution_count="48">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">"loss"</span>],label<span class="op">=</span><span class="st">'training'</span>)</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">"val_loss"</span>],label<span class="op">=</span><span class="st">'validation'</span>)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>plt.legend()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-22-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Compared to the previous two models, <code>model3</code> appears to perform the best, because its accuracy ranges between 97% and 97.31% towards the last 10 epochs. Though it’s not as high as the other two models, <code>model3</code> is able to consistently score at least 97% validation accuracy. Whereas the other two models often fluctuate between 96% and 97%.</p>
</section>
<section id="model-evaluation" class="level2">
<h2 class="anchored" data-anchor-id="model-evaluation">4. Model Evaluation</h2>
<p>We will now use <code>model3</code> to test my model performance on unseen data.</p>
<div id="DDH0tRWNoIVu" class="cell" data-outputid="709a1839-4fc2-4d0a-b8cc-12a7b463ab0d" data-execution_count="51">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load test data</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>test_url <span class="op">=</span> <span class="st">"https://github.com/PhilChodrow/PIC16b/blob/master/datasets/fake_news_test.csv?raw=true"</span></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>test_data <span class="op">=</span> pd.read_csv(train_url)</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>test_data.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="51">

  <div id="df-814e4289-ee6d-41a8-be3b-9d206a019750" class="colab-df-container">
    <div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Unnamed: 0</th>
<th data-quarto-table-cell-role="th">title</th>
<th data-quarto-table-cell-role="th">text</th>
<th data-quarto-table-cell-role="th">fake</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>17366</td>
<td>Merkel: Strong result for Austria's FPO 'big c...</td>
<td>German Chancellor Angela Merkel said on Monday...</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>5634</td>
<td>Trump says Pence will lead voter fraud panel</td>
<td>WEST PALM BEACH, Fla.President Donald Trump sa...</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>17487</td>
<td>JUST IN: SUSPECTED LEAKER and “Close Confidant...</td>
<td>On December 5, 2017, Circa s Sara Carter warne...</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>12217</td>
<td>Thyssenkrupp has offered help to Argentina ove...</td>
<td>Germany s Thyssenkrupp, has offered assistance...</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>5535</td>
<td>Trump say appeals court decision on travel ban...</td>
<td>President Donald Trump on Thursday called the ...</td>
<td>0</td>
</tr>
</tbody>
</table>

</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-814e4289-ee6d-41a8-be3b-9d206a019750')" title="Convert this dataframe to an interactive table." style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"></path>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-814e4289-ee6d-41a8-be3b-9d206a019750 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-814e4289-ee6d-41a8-be3b-9d206a019750');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


<div id="df-d94cb087-a28b-4a28-9e47-c7dbb8ddaec8">
  <button class="colab-df-quickchart" onclick="quickchart('df-d94cb087-a28b-4a28-9e47-c7dbb8ddaec8')" title="Suggest charts" style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 0 24 24" width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"></path>
    </g>
</svg>
  </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

  <script>
    async function quickchart(key) {
      const quickchartButtonEl =
        document.querySelector('#' + key + ' button');
      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
      quickchartButtonEl.classList.add('colab-df-spinner');
      try {
        const charts = await google.colab.kernel.invokeFunction(
            'suggestCharts', [key], {});
      } catch (error) {
        console.error('Error during call to suggestCharts:', error);
      }
      quickchartButtonEl.classList.remove('colab-df-spinner');
      quickchartButtonEl.classList.add('colab-df-quickchart-complete');
    }
    (() => {
      let quickchartButtonEl =
        document.querySelector('#df-d94cb087-a28b-4a28-9e47-c7dbb8ddaec8 button');
      quickchartButtonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';
    })();
  </script>
</div>

    </div>
  </div>
</div>
</div>
<div id="ABKritCQkAAW" class="cell" data-outputid="4681d935-7b89-4aa2-965b-aa156fd6b13a" data-execution_count="53">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>test <span class="op">=</span> make_dataset(test_data)</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>loss, accuracy <span class="op">=</span> model3.evaluate(test)</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test Loss:"</span>, loss)</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test Accuracy:"</span>, accuracy)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>225/225 ━━━━━━━━━━━━━━━━━━━━ 2s 10ms/step - accuracy: 0.9737 - loss: 0.1090
Test Loss: 0.10588612407445908
Test Accuracy: 0.9754109382629395</code></pre>
</div>
</div>
<p>It appears that <code>model3</code> managed to get a test accuracy of 97.5%, which is great!</p>
</section>
<section id="embedding-visualization" class="level2">
<h2 class="anchored" data-anchor-id="embedding-visualization">5. Embedding Visualization</h2>
<p>Let’s visualize and comment on the <em>embedding</em> that <code>model3</code> learned.</p>
<div id="vU-UIiJ4wm2u" class="cell" data-execution_count="61">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># to display plotly plots on quarto</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly.io <span class="im">as</span> pio</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>pio.renderers.default<span class="op">=</span><span class="st">"iframe"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="2IdA13uDodQk" class="cell" data-outputid="87b93b23-3ee4-49a9-a20e-2217796ee4d5" data-execution_count="60">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly.express <span class="im">as</span> px</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>weights <span class="op">=</span> model3.get_layer(<span class="st">'embedding'</span>).get_weights()[<span class="dv">0</span>]</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>vocab <span class="op">=</span> title_vectorize_layer.get_vocabulary()</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>reduced_weights <span class="op">=</span> pca.fit_transform(weights)</span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a>embedding_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">'word'</span>: vocab,</span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">'x0'</span>: reduced_weights[:, <span class="dv">0</span>],</span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">'x1'</span>: reduced_weights[:, <span class="dv">1</span>]</span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> px.scatter(embedding_df,</span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a>                 x<span class="op">=</span><span class="st">"x0"</span>,</span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a>                 y<span class="op">=</span><span class="st">"x1"</span>,</span>
<span id="cb32-20"><a href="#cb32-20" aria-hidden="true" tabindex="-1"></a>                 hover_name<span class="op">=</span><span class="st">"word"</span>,  <span class="co"># shows the word on hover</span></span>
<span id="cb32-21"><a href="#cb32-21" aria-hidden="true" tabindex="-1"></a>                 title<span class="op">=</span><span class="st">"2D PCA of Word Embeddings"</span>,</span>
<span id="cb32-22"><a href="#cb32-22" aria-hidden="true" tabindex="-1"></a>                 width<span class="op">=</span><span class="dv">800</span>,</span>
<span id="cb32-23"><a href="#cb32-23" aria-hidden="true" tabindex="-1"></a>                 height<span class="op">=</span><span class="dv">600</span>)</span>
<span id="cb32-24"><a href="#cb32-24" aria-hidden="true" tabindex="-1"></a>fig.update_traces(marker<span class="op">=</span><span class="bu">dict</span>(size<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb32-25"><a href="#cb32-25" aria-hidden="true" tabindex="-1"></a>                              line<span class="op">=</span><span class="bu">dict</span>(width<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb32-26"><a href="#cb32-26" aria-hidden="true" tabindex="-1"></a>                                        color<span class="op">=</span><span class="st">'DarkSlateGrey'</span>)),</span>
<span id="cb32-27"><a href="#cb32-27" aria-hidden="true" tabindex="-1"></a>                  selector<span class="op">=</span><span class="bu">dict</span>(mode<span class="op">=</span><span class="st">'markers'</span>))</span>
<span id="cb32-28"><a href="#cb32-28" aria-hidden="true" tabindex="-1"></a>fig.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<meta charset="utf-8">

    <div>            <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG"></script><script type="text/javascript">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: "STIX-Web"}});}</script>                <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
        <script charset="utf-8" src="https://cdn.plot.ly/plotly-2.35.2.min.js"></script>                <div id="d9471c33-c12c-4e43-894d-adda76c9b211" class="plotly-graph-div" style="height:600px; width:800px;"></div>            <script type="text/javascript">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("d9471c33-c12c-4e43-894d-adda76c9b211")) {                    Plotly.newPlot(                        "d9471c33-c12c-4e43-894d-adda76c9b211",                        [{"hovertemplate":"\u003cb\u003e%{hovertext}\u003c\u002fb\u003e\u003cbr\u003e\u003cbr\u003ex0=%{x}\u003cbr\u003ex1=%{y}\u003cextra\u003e\u003c\u002fextra\u003e","hovertext":["","[UNK]","trump","to","video","the","us","for","of","in","says","on","a","and","is","obama","with","house","watch","hillary","his","about","new","after","white","clinton","president","trump’s","just","at","by","bill","from","who","russia","this","out","he","state","court","north","republican","over","it","senate","her","as","election","donald","calls","him","are","korea","will","breaking","that","media","news","black","how","be","vote","police","not","republicans","tax","why","campaign","gop","–","was","you","muslim","trumps","may","gets","has","up","obama’s","one","deal","democrats","china","iran","what","former","down","against","tweets","attack","back","security","people","government","un","russian","have","talks","party","first","plan","fbi","top","chief","eu","speech","senator","pm","judge","congress","war","cnn","twitter","syria","fox","democrat","tells","they","america","ban","leader","no","their","make","say","military","man","law","during","south","report","would","minister","makes","sanders","it’s","could","when","million","take","liberal","shows","probe","americans","racist","brexit","two","tweet","she","presidential","like","official","supreme","more","into","factbox","get","healthcare","goes","nuclear","wants","sanctions","hillary’s","putin","if","woman","gun","foreign","poll","being","political","governor","border","rally","american","women","illegal","host","go","cruz","off","attacks","an","islamic","show","obamacare","wow","want","national","them","support","response","meet","fight","syrian","supporters","debate","day","race","all","bernie","killed","time","rights","our","german","help","urges","old","lawmakers","he’s","group","crisis","conservative","policy","next","call","turkey","most","meeting","antitrump","states","see","candidate","uk","budget","gives","claims","ryan","must","because","mexico","fake","while","asks","your","win","saudi","room","leaders","details","world","school","refugees","students","don’t","travel","mayor","death","administration","stop","plans","panel","opposition","can","way","going","department","visit","trade","texas","takes","secretary","right","officials","hilarious","cops","reporter","move","got","general","big","years","won’t","pick","defense","before","air","end","email","comey","we","sources","press","climate","city","warns","so","head","caught","aid","ties","supporter","exclusive","arrested","left","did","democratic","wall","ted","rules","justice","john","should","protesters","money","voters","violence","than","still","interview","huge","paul","immigration","free","seeks","made","kill","federal","shocking","really","major","emails","year","work","truth","use","said","live","leftist","here’s","but","washington","case","tillerson","reform","open","only","give","conservatives","tv","reason","family","director","times","lawmaker","bid","ahead","lie","last","iraq","high","boiler","sexual","secret","presidency","lives","team","now","key","i","health","do","college","can’t","york","dead","britain","voter","speaker","push","need","jerusalem","home","told","order","nominee","myanmar","lawyer","social","post","isis","investigation","image","george","catalan","threatens","merkel","army","shooting","pence","never","florida","coalition","threat","terrorists","puerto","forces","ep","boom","run","office","list","lies","flag","fire","dnc","control","change","business","attorney","ready","protest","mccain","bomb","billion","terrorist","ruling","lol","japan","face","ever","rohingya","peace","latest","funding","doesn’t","cuba","british","2016","own","message","iraqi","germany","force","destroys","decision","adviser","muslims","legal","korean","fired","another","again","rico","release","parliament","keep","job","great","cut","source","know","israel","independence","amid","votes","story","senators","discuss","statement","public","jobs","intelligence","chair","california","arrest","sean","or","msnbc","lead","charges","week","terror","kremlin","blasts","backs","asked","aide","tries","refugee","needs","called","behind","used","trying","power","nyc","macron","hate","had","even","chinas","chicago","busted","best","“i","wife","violent","using","clinton’s","bad","“the","were","three","son","protests","pay","found","flynn","defends","agency","special","seek","missile","hurricane","himself","girl","full","bombshell","slams","matter","march","cop","been","3","very","scandal","real","radical","proves","nfl","london","internet","didn’t","despite","congressman","bush","away","action","young","voting","sex","set","kills","fraud","children","benghazi","victims","under","tell","refuses","possible","kids","hollywood","hold","france","denies","dem","cia","admits","ad","start","sign","rubio","men","making","hit","cuts","committee","comments","act","thing","shut","rep","orders","inauguration","facebook","elections","believe","awesome","al","trip","these","sees","rule","reveals","reports","released","rejects","program","planned","much","mcconnell","lying","kurdish","hits","evidence","claim","barack","warren","vows","turkish","street","shot","service","saying","rape","michelle","let","images","french","five","executive","drops","disgusting","dc","xi","wins","transgender","review","return","question","put","near","issues","history","hack","corruption","brutal","without","uses","think","stunning","strike","rant","pope","moore","mike","jail","ivanka","hilariously","good","gave","does","debt","days","blames","audio","assault","announces","agree","10","whoa","threats","summit","sarah","passes","middle","look","king","hell","groups","forced","final","female","exposes","epic","east","country","child","approves","angry","ambassador","yet","viral","victory","star","seen","rips","repeal","paris","liberals","kellyanne","flashback","envoy","convention","calling","activist","4","warning","strikes","sessions","senior","russias","questions","pressure","pelosi","oil","murder","massive","least","kelly","epa","destroy","criminal","close","arms","venezuela","thousands","spokesman","other","ny","likely","jr","issue","every","agenda","2018","water","too","test","she’s","running","protect","part","offers","erdogan","demands","crowd","break","abortion","trial","they’re","spending","since","role","nancy","millions","michigan","leave","illegals","hard","gay","finally","doj","come","citizens","challenge","arabia","“we","second","schools","picks","philippines","pentagon","nato","names","nafta","joe","hopes","fighting","energy","conway","congressional","catalonia","biden","afghan","union","ukraine","town","thinks","terrorism","name","member","mattis","leaves","join","immigrants","global","getting","fund","faces","effort","church","chris","chairman","ben","battle","alien","activists","1","yr","yemen","working","workers","words","united","transition","student","spicer","spain","photo","perfect","offer","megyn","killing","johnson","irma","insane","future","fck","cyber","confirms","conference","aliens","alabama","911","wikileaks","university","talk","taking","system","suspected","puts","private","michael","members","lebanon","labor","hacking","four","fed","exposed","elizabeth","destroyed","cnn’s","ceo","boy","block","5","vp","turn","turkeys","target","step","staff","resign","points","navy","loses","immigrant","hearing","hannity","fear","crooked","christmas","carson","breaks","australia","around","announcement","accuses","2","urge","steps","stage","soros","remarks","parties","mocks","militants","migrants","little","letter","guest","friend","friday","find","far","everyone","embassy","economic","deputy","defend","council","blame","weapons","train","some","sheriff","request","percent","oops","mueller","lose","literally","laws","intel","fans","company","coal","car","ask","already","actually","where","troops","tried","today","stand","something","signs","perfectly","oregon","movie","might","market","manager","james","irish","held","heads","funds","food","explains","care","cabinet","brilliant","anchor","syrias","stay","speak","sht","sea","responds","prison","pastor","northern","moscow","moment","melania","mark","line","flint","drug","detroit","dems","dangerous","crazy","confederate","civil","chinese","candidates","canada","antifa","west","try","speaks","rich","ria","revealed","professor","parenthood","owner","ohio","night","mass","life","human","foundation","ends","embarrassing","coming","baltimore","allies","20","wrong","worst","voted","uks","tucker","totally","telling","steve","same","roy","releases","referendum","play","number","mom","harassment","firm","financial","employees","due","doing","daughter","dad","cities","capital","between","allegations","15","100","well","waters","unhinged","things","term","sue","soldiers","seth","save","reelection","potential","politics","parents","palin","moves","lawsuit","israeli","iowa","guns","giving","furious","frances","finds","bring","boost","asking","appeals","any","actor","access","6","zimbabwe","victim","taiwan","sick","sent","reutersipsos","reporters","picture","pakistan","o’reilly","officer","obamas","my","launches","jeanine","illinois","girls","front","eyes","event","eus","europe","efforts","economy","disaster","conspiracy","community","comment","brutally","britains","book","bank","asia","abuse","update","tensions","super","streets","soon","shuts","sanctuary","romney","resigns","residents","racism","quit","prosecutor","proof","pass","paid","mugabe","mexican","jailed","highlights","henningsen","happened","guy","declares","crime","comes","charged","charge","changes","carlson","become","bangladesh","arrests","allow","accused","8","‘the","winning","wanted","videos","throws","sunday","six","russians","results","raise","philippine","overhaul","months","meltdown","maxine","love","lost","living","ireland","important","hope","hariri","game","father","egypt","demand","data","christian","better","bans","australian","attacked","answer","amnesty","agencies","50","virginia","vietnam","thugs","thought","testimony","teen","taxes","talking","send","rightwing","red","record","reach","palestinian","pact","nomination","news’","murdered","long","less","journalist","its","hacked","germanys","freedom","focus","fix","feds","failed","desperate","class","christie","baby","african","absolutely","zimbabwes","worse","vs","trump”","then","teacher","spanish","socialist","rnc","remove","recount","quits","prince","players","outside","mother","meets","manafort","looks","launch","iranian","industry","humiliates","homeland","ground","gov","fires","finance","electoral","education","early","december","boycott","board","blow","base","appeal","anthem","america’s","7","you’re","went","watchdog","waiting","vice","undercover","turns","tuesday","tough","thursday","taxpayer","suspect","sends","reid","reaction","qatar","praises","position","popular","patrick","opens","month","missing","many","kushner","kenya","international","information","hurt","harvey","hand","green","gowdy","firing","experts","enough","endorsement","done","diplomatic","criticism","counsel","continues","concerned","companies","choice","cannot","borders","billionaire","bathroom","attend","attempt","asylum","ally","agents","afghanistan","visits","veteran","trey","took","threatened","threaten","third","there","targets","surprise","strong","serious","sentence","screenshots","rebels","place","netanyahu","nations","maher","lady","journalists","isn’t","inside","injured","hundreds","golf","expects","elected","drop","draws","dollars","dept","delay","dallas","crackdown","communist","chuck","central","bundy","bannon","avoid","armed","address","17","13","“you","worker","word","women’s","weighs","wearing","visa","unity","taxpayers","supporting","stupid","somali","small","sets","schumer","replace","religious","relations","raises","promises","powerful","nbc","marriage","low","loss","libyan","leaks","leadership","kkk","kerry","joy","joins","hosts","farright","facts","ethics","eastern","donations","dispute","corporate","continue","check","blacklivesmatter","aides","agrees","12","11","wisconsin","wage","veterans","study","seeking","scott","returns","regime","protester","propaganda","progress","posts","plane","nyt","nothing","nation","militant","migrant","met","meddling","mays","lynch","longer","lied","kurds","koreas","hypocrite","husband","humiliated","hotel","hispanic","hateful","gas","false","expected","european","drive","disturbing","die","detained","delivers","cover","concerns","cash","campus","broke","body","blocks","biggest","audience","assad","allowed","alleged","agent","who’s","usa","trumpcare","treasury","threatening","testify","supports","storm","shooter","rise","reality","read","pushes","prove","polls","nearly","monday","mainstream","libya","legislation","leaked","leading","lavrov","jimmy","jeff","hysterical","harry","hands","hammers","half","guilty","explain","exit","eric","endorses","emergency","dialogue","criticizes","condemns","compares","committed","commerce","charity","center","carolina","building","blacks","attacking","appears","airport","ads","account","abe","30","25","warned","van","unreal","thug","suicide","spying","scam","san","sales","risk","riots","reuters","removed","relief","proposes","process","probes","prime","priceless","point","plot","person","others","nightmare","newspaper","mnuchin","ministry","local","kim","influence","huckabee","here","happen","forward","families","expert","dies","defending","decide","credit","cooperation","controversial","complete","breitbart","bizarre","attempts","april","anyone","amazing","africas","advisor","2017","“racist”","you’ll","whether","w","sweden","suspends","suggests","stance","seven","sec","respond","relationship","records","ratings","problem","price","planning","phone","orlando","options","marco","looms","lee","leads","kasich","japans","islamist","investment","india","idea","he’ll","helped","google","gonna","fuel","files","fears","fan","dossier","documents","diplomats","defeat","david","countries","clash","cites","charlottesville","camp","bus","brazil","blast","admit","actress","actions","9","18","“if","—","viewers","vegas","treatment","total","teachers","swedish","susan","straight","station","starts","spy","sports","situation","silence","shutdown","shoot","search","resignation","region","poor","phony","pennsylvania","pathetic","path","outrageous","nra","nazi","nails","memorial","late","keeps","jones","jersey","irs","hunt","hot","helping","hear","guess","gingrich","feel","expose","exactly","environmental","deals","courts","coup","confident","commander","collusion","citizen","chaos","chance","cancels","buy","bombing","aren’t","across","accidentally","accept","“he","‘white","‘fake","won","whining","whines","welfare","welcomes","weeks","trudeau","tower","torture","tom","tim","themselves","that’s","tears","taken","sudan","strategy","stephen","snl","showing","sharpton","sell","robert","road","ridiculous","raqqa","putting","pulls","promote","priebus","presidents","policies","pledge","photos","past","parade","outrage","online","officers","nsa","nominate","mosque","mock","militia","mi","me","links","leaving","jeb","japanese","irans","independent","hypocrisy","holds","holding","halt","graham","georgia","fit","fellow","everything","duterte","drone","donors","dirty","detains","deep","deadly","crimes","commission","clintons","christians","cancer","camera","burn","brussels","brother","blocked","blaming","bills","banned","baghdad","arizona","approve","apart","america”","aim","abc","2015","worked","wednesday","view","trust","truck","through","there’s","taps","tape","store","standing","speaking","southern","someone","sexist","safe","ross","rice","restaurant","remain","regional","primary","numbers","newt","mn","memo","lower","lot","losing","limits","lawyers","kurdistan","kimmel","kidding","kicked","kansas","june","judges","insurance","info","indonesian","increase","hours","hiding","hezbollah","having","handed","graft","gone","given","gains","friends","floor","flags","famous","fair","fail","easy","domestic","discussed","disabled","dinner","cuban","crash","consider","congresswoman","conflict","collapse","closed","citizenship","ca","briefing","boss","bombers","blood","beijing","beautiful","beating","based","banks","ballistic","backing","ago","24","“i’m","“it’s","zika","within","withdrawal","wire","willing","website","wealthy","vatican","unlikely","tx","todd","those","thanks","tech","surveillance","shreds","scheme","rush","rock","rhetoric","reportedly","rate","prosecutors","proposal","promise","problems","politico","poland","player","pipeline","paying","owned","openly","opening","once","oklahoma","nominees","network","myanmars","moving","movement","mob","minimum","measures","majority","listen","light","killer","joke","joint","jackson","italian","islam","hospital","historic","happy","gulf","guard","governors","gorsuch","glorious","flight","fighters","fails","explodes","explode","endorse","demanding","declaration","de","critics","course","confronts","cold","cause","caucus","castro","career","burns","brings","brazils","brave","berkeley","beat","babies","arab","appearance","announce","agreement","accusations","“white","witch","which","we’re","warrant","warming","visas","vet","usbacked","trumprussia","trash","toward","tests","targeted","tantrum","sure","sued","stunned","stock","stealing","stands","spent","server","sending","seat","scotus","resume","replacement","reject","reforms","reasons","protrump","progressive","privacy","peaceful","opposes","nuts","neil","needed","nasty","n","minutes","mind","mean","linked","las","knows","kenyan","keith","karma","judiciary","jewish","i’m","it”","island","infrastructure","including","incident","harvard","happens","guests","gift","form","football","following","flood","firms","field","falls","failure","facing","entire","egypts","diplomat","dhs","delegates","critical","create","couple","cost","convicted","considering","colbert","chelsea","cheer","ceasefire","becoming","becomes"],"legendgroup":"","marker":{"color":"#636efa","symbol":"circle","line":{"color":"DarkSlateGrey","width":1},"size":5},"mode":"markers","name":"","showlegend":false,"x":[0.09772912,1.0373915,9.175269,-1.7453207,11.288783,-17.246557,-8.997197,-2.5533774,-2.6579356,-1.2167647,9.777895,0.5006354,-9.401582,3.0295799,6.5611477,18.084408,0.24373254,-7.248018,15.649918,16.397963,-2.562586,-0.26234156,-5.449463,0.8968501,0.10440096,3.5206501,-3.554696,-4.700724,-2.4262881,8.923689,-0.30377126,-0.05503738,-1.0536549,1.9375436,1.0145421,-3.8754084,3.8402822,-7.97047,-2.1996548,-6.3777704,0.11388454,-12.062453,-0.36282408,-0.21948028,-8.059695,0.7277447,-6.4927936,-8.766684,-3.3879685,-0.5732806,3.90718,1.8237422,-1.9193187,0.7550361,-0.21506695,5.7212114,2.4359877,7.457359,9.395386,0.8665714,-2.9868588,0.60213935,-1.8843563,1.6491361,4.3887477,-7.988589,0.7523421,-4.552155,22.417269,-11.65656,1.4377903,-0.18486011,7.6882997,-37.614338,1.0817744,7.8978667,3.2916265,5.434282,-3.2496684,6.423831,-3.2256289,0.69028306,-9.834715,2.2584364,-0.12444319,-8.153,-0.97241044,-0.97482264,0.2925754,1.7881808,5.2633924,-1.3911254,0.9091767,-11.594807,-1.6812955,2.2089658,-0.12074435,-12.274636,0.7159624,-3.0965493,-2.029914,9.785847,-2.8305767,-6.916701,-10.529375,0.7786455,-3.9786568,4.708773,2.747426,-3.2070117,-0.80708647,-3.4656897,-6.648573,4.3213243,14.364945,-0.5902468,4.103948,-5.6382875,17.276888,-1.5307924,-6.2945204,-0.49552292,0.40388748,3.8677237,0.43729702,-0.20088746,5.0242624,-0.36951378,0.92637837,-7.2255735,4.7819324,-1.035387,-16.692509,5.112706,3.8522832,-2.5892463,-1.6968038,-3.5087264,-4.851923,2.8311307,5.8748083,5.460255,-2.987463,10.855722,13.456401,-9.88558,-5.699354,-0.0727132,-4.370213,-12.150983,16.162804,-2.9927902,2.8439224,16.939974,-0.015118182,-3.4859958,8.252882,-10.17082,4.705664,0.3123168,2.4146903,-2.7027097,-4.0792236,-2.1385345,-11.553557,7.694163,7.4429574,-6.72765,-7.198931,1.9961653,-0.34462604,-2.3706784,-1.5289263,-2.0735452,14.272914,-2.1287072,5.7468233,7.605348,9.063751,-0.07622594,2.382526,-5.428521,-3.4581025,-3.8698275,5.9788823,-1.939591,4.9110146,5.194757,-2.2248473,0.48203155,-2.5296526,4.1891623,-4.9506345,2.6176183,2.2585862,-1.3360527,-4.7099442,3.144634,-4.62935,4.4529014,7.4658165,-11.838582,6.835551,-4.363876,-5.8363795,-5.97337,-1.3301653,0.45284835,3.5877657,-7.0814357,-4.1600337,-4.6367607,-7.350816,-3.2146416,-0.7688054,-5.5943446,2.6045032,-10.165479,-3.1079912,-2.6013014,4.9779634,-4.909604,3.6478245,-2.8616207,5.6851726,-5.181583,0.5587853,5.912264,2.5562367,-0.9740951,-0.76840806,-2.9902158,3.845607,-5.501999,4.5931096,-1.98698,-0.1881959,-6.2491784,5.2042184,-5.856166,-1.2498376,1.4190879,2.90907,5.416907,2.865211,-0.8753706,-0.48109263,6.0959663,0.5627898,2.6678205,4.8299603,-4.1291695,-17.88446,-11.684766,-1.4028766,7.4982777,5.750893,5.704213,-3.8057194,-12.121091,4.219149,3.0235271,-1.4559067,9.648903,-1.1386898,5.266627,8.972407,5.782658,-1.0343682,11.185321,-2.4094288,1.0553874,-6.0739074,-4.074955,-1.4421469,-1.3791156,0.67082965,-4.9356728,-2.0908322,1.3489138,3.003076,-19.766726,-1.6171246,12.206742,4.720799,-2.5919814,2.884394,2.397031,-5.351113,4.9659986,-2.835685,-3.8025024,1.3920273,4.3318324,-1.9004352,6.3869486,1.5366054,-6.5694056,1.0724686,2.3437238,-6.437761,-1.7179755,8.110436,-1.6533642,1.803185,9.586499,-4.6465335,-2.260233,4.475968,-1.5593618,2.370755,5.3747725,2.2496314,2.6813438,3.825186,-3.7072842,2.8563397,4.8552012,0.97440624,7.968558,12.501389,-4.654152,3.462789,-7.945111,-1.3810719,11.246967,1.8484077,-34.38388,7.1158752,3.643627,-0.15540908,-5.4013615,5.7096305,-0.5411243,-1.7329048,-6.1789985,1.4726127,-0.9629631,2.8440645,-0.39288056,-5.2840757,7.5892143,2.0696294,-2.0229695,5.3079615,-5.9634423,-5.9461646,-9.031983,7.4405622,-7.1238956,-2.1173923,-0.725891,11.694155,-0.09109995,6.791771,-1.7258273,7.533888,3.89692,3.9155648,-2.5147755,-24.952951,-2.4130263,3.3282213,1.331862,-3.449641,-1.5830834,0.53801215,-10.191504,8.208973,-2.5219793,-1.7597948,2.4761057,-0.66396534,-0.13860014,-9.224288,3.5284212,-1.1544038,-14.176809,-4.123097,-3.9199152,3.9333584,13.195186,3.0299027,1.5238334,3.1984832,-11.715153,-1.2795086,-7.3775754,-4.583068,8.152807,-1.9545649,6.0068526,-2.6328208,-6.0063477,4.1968007,9.582535,-5.1799073,-5.909668,2.625567,-0.13461986,-0.12659341,-3.6193316,3.973788,6.474531,8.7549515,-0.32497758,8.826271,-2.8906705,2.7277322,-1.4048047,-1.596708,-1.357075,1.3504672,6.840737,-5.542431,-6.1220756,8.354793,-9.613861,1.7155204,-9.210666,0.71107125,5.718191,-12.095045,-6.0980797,-1.3800746,-2.8250458,-2.128307,-6.5707035,-6.8807054,1.9572003,-6.78425,1.1844292,-2.6012375,-5.595446,1.2756352,1.897582,-0.53634816,-3.0365481,2.933495,0.2760671,-0.5944471,-0.49943578,4.723124,3.8879282,-5.533926,2.5422654,-13.7851095,5.4295125,1.071935,0.8120086,-0.27354485,-2.598131,12.661804,-1.259671,-9.277032,-6.677301,-0.3515194,10.202294,-9.816274,-2.057299,-9.301034,-0.7948592,-0.8217891,2.8327026,0.9717001,-2.781982,-0.914263,4.3023567,5.713624,4.920636,-4.9831095,-3.8545132,-5.1841426,10.313335,-5.67118,-1.3941255,0.99541605,1.5627669,-4.8967037,3.466254,1.8963776,3.0720878,-3.3331726,0.89742863,2.4808962,4.601447,-2.5180538,5.3029795,-11.780612,11.246986,-0.50729084,16.98488,-7.647205,3.1033673,5.5094633,5.4727335,5.4970465,1.7275918,2.9982228,4.361636,2.257073,6.349591,-5.098943,-15.575121,-5.4588747,-0.47845098,-3.1183498,2.630247,0.831306,1.028452,2.7812893,-8.999792,2.8096704,-3.4704046,-2.8425333,-6.2070384,2.4479406,5.932658,4.113737,4.466052,0.27347633,8.984337,0.6990837,6.137584,2.9503849,3.7633212,-6.5140166,-0.44500032,2.81719,4.1181374,6.4325895,3.161684,-6.505901,-4.6916146,6.0450163,1.1083357,5.3412113,4.4573145,2.374609,1.488753,1.7016785,2.962935,-0.5641815,-2.9839168,-1.0677226,4.8272886,-0.6576649,4.9063396,0.8983966,-7.441583,7.3238873,1.3621992,-3.5152006,4.3598766,6.8044453,-2.0419486,-7.561434,-8.386594,1.8536057,7.257723,2.9537606,3.0325885,-0.5619943,-0.1348581,-1.2287742,0.69997644,1.4180307,1.3417214,-0.75953996,-3.8669133,-1.5943426,2.3321476,9.116885,1.7643471,16.25913,-0.0037108362,-0.3009547,5.0655932,-1.6392695,7.277675,5.1727824,2.828665,-0.6727482,-5.450131,0.37930784,-7.3598523,5.1041083,6.272188,3.2327762,-1.8147624,0.9025148,3.7614672,6.254929,-0.4857533,5.6846333,-9.546403,2.4663846,3.232298,7.463415,-5.9388695,5.7423058,-3.5521066,-9.466869,1.6665578,4.6144876,-0.11789736,-6.7156568,0.41596344,-1.787599,12.157043,1.8409581,-8.220418,-1.7467089,-1.5899471,0.617272,6.3222346,8.504056,-8.93356,-2.4896405,-2.4077623,-7.072787,-2.7577581,5.7096076,3.8192265,-1.412077,-1.1494386,4.616575,3.5279582,-6.6892815,-3.0262702,1.2032315,0.28121212,5.5030904,3.992634,1.1638801,6.5172787,2.3967807,3.7177408,0.46992055,0.09113258,2.5830283,4.571023,4.792348,2.7847507,1.3857079,-0.95676994,-2.877244,-2.528422,0.6866605,2.7275264,-1.1707563,3.0426219,-1.8222197,1.9957347,5.3239202,-3.896759,-0.797583,-1.7633889,2.4801133,6.239029,-1.0484774,4.084578,-7.506335,2.360233,-1.3892809,3.2732146,4.1799397,4.096976,-2.9357462,-3.0484648,1.9664564,0.94802475,5.0288496,-1.0291104,4.121919,1.2431153,-4.2578206,-1.8623403,-1.8224205,-15.978171,-5.6019998,0.5683243,4.3239546,2.928943,0.81335616,-2.613732,-1.7149395,3.4843109,0.40861872,3.2384856,2.1182792,-2.313192,3.6867902,-2.785732,-9.499746,-1.3218718,-3.2169921,5.009292,-8.730096,0.6778879,4.815197,0.51991415,5.499464,1.6949549,6.623909,5.5299735,-5.4164643,4.671625,-8.404285,-4.558561,-13.551576,-1.8825122,6.9713554,-0.95851576,5.329344,-2.2497091,9.527557,2.7469232,-9.405197,0.17518935,2.969793,-2.1872716,-1.9452786,2.3586192,1.0011406,-3.4864821,-1.0402547,-8.4917555,1.0691165,0.53183687,1.1845078,1.9097228,-8.984293,0.45074335,-2.3315985,-5.627436,-3.7051754,3.5943964,1.2055317,6.2075353,1.2418853,7.2701597,0.61075664,0.0044837594,5.906921,7.610756,4.803527,4.514548,-5.260554,-5.9764433,1.6306465,-5.5256357,-1.5117671,-2.0161138,-5.7963367,3.293579,-0.8533715,0.4724382,-3.4818826,7.928018,-1.8970643,-4.0571613,-2.5215127,4.9422703,-4.286153,-11.7695465,5.147108,-1.5182815,-5.30051,-7.9205337,-3.2937086,6.3414235,1.5821201,2.2925956,5.5466523,-3.0325406,-0.9963684,0.79538274,-5.6225567,-0.9839916,5.1803555,-2.2829976,-3.1476467,4.0360513,1.2206168,5.4013457,-4.0092688,0.48400512,-2.2521088,5.3339396,-2.5630958,-2.1197145,0.7148055,-3.5605931,1.8271797,-5.1179657,8.633732,-3.408701,-5.1782947,4.3115644,1.3588063,-13.095267,9.070041,5.309652,-1.0376793,4.302335,-2.2180207,2.805664,-7.7224517,7.624539,-2.4083858,6.2340574,-1.8856921,-0.11593109,-3.3446743,9.6754265,0.28225294,8.194719,6.224688,-2.693084,4.884542,3.1332967,-1.1254765,-5.5942125,2.4696283,-3.6528666,-0.35286972,1.6670926,-10.233126,-2.7585697,1.8573639,-4.662878,-0.85790217,0.34193894,-3.126552,2.2464926,-1.2295508,0.36616752,3.7777512,1.935416,3.7004955,1.1045616,2.1648684,-1.2452769,1.2505766,-1.7089375,-1.7413639,-2.840568,-3.1402688,0.3180969,1.2276869,5.5356827,-0.018502086,7.457678,2.0890524,1.0592072,-1.0105121,4.1185913,-0.74253714,-4.685114,-1.759167,-0.91533935,-3.5339806,2.757645,-3.4007783,-2.2838855,-3.406909,9.434216,-1.4959073,-8.003079,0.19252601,-12.182696,0.43610868,3.9295356,-0.40104425,6.4876747,5.1481686,-16.463205,2.3656917,0.99154663,7.627361,3.5718305,-5.82189,-3.8929565,4.142962,2.0874186,4.9253407,0.25708988,1.2652106,-2.3829534,12.588166,-2.2315884,-9.902851,2.255434,3.2011247,2.6258216,8.491668,-1.5006601,2.3588748,0.99913764,-3.5552788,-1.2531782,-3.1290894,2.927294,3.5113587,13.256691,0.2898415,-0.56583107,2.5463486,9.749693,5.9141536,8.821919,-1.3059071,4.639334,5.6676126,2.514673,4.561929,-10.360534,-2.079881,2.0808005,-6.8290434,-3.8837094,-1.8162788,-3.114113,-2.4866433,7.57883,6.007999,-4.8686924,5.3753805,3.1716735,-3.0830843,0.31736967,4.3277273,5.0279393,-5.333164,4.671332,0.56315804,-0.18874928,-8.782609,-6.6787643,5.2071447,2.8470213,4.3687468,3.7522542,2.6376562,-5.4461994,6.7650056,1.0971633,0.832284,7.1993084,9.644582,-2.0534537,-5.3693714,-4.018806,-5.1140676,4.6395926,-2.1129515,3.0705419,4.865552,5.8904424,-8.504935,7.5787315,1.7874887,9.09756,1.2490519,-0.29124495,7.0099444,1.0685942,2.823196,-0.9652226,4.4485755,-3.0621808,-13.775866,4.261695,6.788241,-3.951927,-2.746909,5.8854637,1.9338851,2.8465357,-0.5877204,8.533099,2.3100228,5.410838,4.421169,-1.1598477,1.4053828,1.5561657,-9.131037,0.8460356,3.9252317,3.5101693,-0.46479657,-2.448702,-5.8970885,3.3971834,-5.118514,1.5790734,1.7597263,1.3740572,-3.849084,-11.215835,-0.28927165,-6.254457,-3.0718563,-0.21563493,4.810209,3.3605392,4.521781,7.674483,-2.0995739,-0.618881,-4.6653256,4.939675,-0.15109736,-1.434606,-3.7099028,0.91975355,-0.20708673,3.4351025,-2.2715404,-3.4530709,-1.9997686,-2.6856558,3.5037973,2.3431265,2.147964,-2.7495859,2.050228,1.6909847,-6.0347185,4.9318643,-4.5094595,-4.1105843,1.4454702,-1.361362,1.8750947,-8.751432,3.8599455,-3.5135255,-0.63722754,1.7926655,-3.7211895,-14.798845,5.801291,-3.859451,2.7428217,4.6291265,-17.674921,-5.3404408,-1.7334613,4.7085505,-4.3541427,1.5377169,2.6996787,1.128671,-1.1578847,1.057162,0.16563329,-1.9558921,-4.8202515,1.0056024,6.6983967,4.43105,-14.7364855,3.316701,-5.3099236,0.21568802,-6.582087,-6.3168235,-1.3534468,0.9673574,-4.2346487,-8.801555,-2.3392382,-0.8517909,2.1970851,3.0727332,1.8538423,-5.773339,-3.8061032,6.0874686,-2.2832444,-7.2698026,2.5362537,-3.0184844,2.1729414,-12.593808,-2.8227925,-3.366776,-2.4766023,8.668597,8.250727,9.942921,-1.1430389,2.5760515,9.449876,1.8654914,-0.43294132,-6.475565,6.957651,2.3829906,-9.418031,-0.1228894,0.0730069,-7.187458,-8.00714,-9.585966,-0.9873351,1.8589029,1.4665865,1.5635083,-9.377759,-1.5282426,5.2947345,0.6650231,0.08941981,-4.617314,-9.19899,-4.269785,1.1317731,5.984696,3.6927135,-0.2430289,3.409501,-8.218003,0.26702508,-0.6601651,-8.572942,1.3249782,0.22275564,-7.7038693,2.013038,-3.3358016,2.17634,3.0110064,-3.1995816,-4.150651,1.6503854,6.038892,2.6510692,-2.993133,-0.7460135,1.373835,-5.1731634,4.9205246,6.6413274,2.4046407,6.412241,0.72363293,5.514983,1.9960647,3.1542525,-0.7082248,-0.42018723,-3.753512,-6.889689,-4.49362,-7.141693,-37.71334,3.4987075,-0.19783807,-1.6243795,-1.20416,-12.6908655,1.7263153,-1.3707366,-1.0829824,-1.0709784,1.1999309,0.93918324,-0.9632498,1.7631462,2.8498518,-2.8412347,0.92797637,-5.968411,5.3555346,-1.1465288,4.882205,3.1012938,0.48073307,1.5936129,1.9606435,-5.6328893,-0.09562516,6.057342,0.42627892,4.5262804,-1.4042342,-5.8634706,1.862957,-2.2681067,-0.17905861,-3.4035442,-0.70725656,2.9079614,0.6182581,3.2401056,-6.127453,-2.1810386,3.2093222,-0.06888741,10.583031,0.35484335,-6.018542,-4.1545115,-0.5644636,-5.7195506,5.357515,0.97968733,1.255248,1.8274677,0.1451743,-4.5358777,1.3611685,-2.2292154,0.51247406,-0.07912147,10.254997,-3.8572297,0.8720962,-4.6696734,5.408473,7.2937703,-16.50622,-2.9346485,-17.353397,7.2824173,1.6185976,2.6102982,6.4531255,2.2999485,-2.5977683,1.2058089,1.3034236,-0.050942898,6.8285956,0.024474055,-11.117847,-0.93612576,-1.2244188,0.35497734,-3.8038309,-4.2926097,3.4347923,0.110444844,0.1409277,0.8632597,1.9062109,4.27765,-0.52884114,-1.9353408,4.8008614,-0.82375133,3.683552,-2.2174635,-6.745685,-0.9807416,6.9428515,-0.2365602,-10.644067,0.90605485,1.0616398,2.1257906,-3.525873,1.1563811,-1.4983581,2.2452428,-2.388202,-5.0478625,4.8897643,-6.273421,-3.56999,2.9703085,-6.9653273,1.2427819,2.208913,4.1868815,-2.9554453,-4.2262206,-1.4171336,2.444611,-1.7795066,3.8139498,-3.2002804,0.8708031,-0.1504179,0.76781285,-1.2417653,-5.5654345,5.2309465,2.939841,-2.980167,-0.34564888,3.4398832,-2.457975,-2.9745102,-1.8810169,-2.66444,0.6568389,-0.048323452,2.0908449,3.980106,6.4089108,-2.6741157,5.2382116,-7.710761,-1.3674864,2.7245555,-6.7944674,8.221713,0.61480165,-1.3383328,-2.0557485,-2.2528315,2.5069184,-0.892138,-1.9181703,0.88621056,4.453003,-0.9008062,1.978764,-1.5574903,4.6383004,-1.5911891,5.4795284,3.3972187,6.7870407,2.8434885,-3.5130007,0.4949648,3.4528031,-3.2978215,-2.2073662,-3.5723786,0.39758012,-0.9362776,-1.2641146,4.2940187,-2.3443532,0.10136053,0.9321995,-3.8292656,0.51033795,-0.95623076,3.5816398,3.4866407,4.9246006,1.6131103,2.5082676,-5.082327,4.860618,1.8447993,-7.7907157,3.4690633,-7.4215794,-1.5798186,4.2122498,4.5136976,3.0712879,-1.928319,-1.0150359,-0.44880232,-1.6048871,2.4394312,-1.8193933,3.0231962,0.3561509,-4.120123,1.7133071,1.6666286,7.220688,1.6448159,3.696791,-5.297184,-4.427924,-0.5931493,5.68124,9.154108,9.775769,-7.9929667,1.4937288,-2.1461465,-2.8721154,-1.6531992,5.1439238,1.1154399,5.8413916,-4.906174,-4.239545,3.7097843,-0.4498686,2.4193804,-0.40575466,1.5555648,6.027315,-5.8608866,2.4060388,-16.160183,-10.742541,-1.3117304,5.8059855,2.9417164,-4.1800857,0.22865018,3.4829783,-2.5050611,4.383263,6.264849,0.44074067,-2.6048498,-3.182489,-2.6095054,-0.39161044,3.9934447,2.3197937,3.8620336,5.051099,-1.391184,7.919749,5.474647,-4.96519,4.921376,-1.3940295,0.08297306,-6.1263256,5.4201093,-0.12275198,3.6550186,13.221821,1.5938684,3.2514532,-6.5483403,-2.6611583,-16.931814,7.038517,-0.6455481,-7.2259703,4.0471625,-2.046172,-0.59161085,2.311952,4.3727927,3.665129,-3.3392596,1.2073351,1.0080467,-3.5020297,-0.9267676,2.7038891,-0.4356086,0.12256858,0.84074295,-3.3076413,-5.671492,-0.50223124,1.3432808,-1.2376862,-0.050523818,-3.1990907,-1.1282053,-1.1899093,1.2595652,-2.6507297,4.2594776,3.3962524,6.947925,-3.4852552,-2.7246675,-1.5263011,-3.4275806,-1.303969,-2.3434367,0.11959648,4.091347,2.413767,3.8458607,-0.651142,1.085914,4.8337445,1.1142079,-3.4666188,-1.7820807,3.480501,-4.7087793,4.429842,1.3150218,-1.0281112,-1.5392668,-3.121562,-9.200744,3.7489913,5.0001187,2.2071543,6.058286,-3.8175282,2.243204,-9.35389,-4.7472153,-14.339573,-3.171296,1.6606226,-0.2731885,3.3631349,5.969192,2.1480384,0.5914173,-0.4936362,0.24599281,0.5414319,1.0182002,1.8040905,-1.2699683,-5.5787225,5.506256,2.1636312,1.667943,5.588102,-0.6199837,3.8451726,11.215742,2.5682185,1.1401882,3.3737931,7.3771467,-0.5522677,0.09744528,-6.3404183,2.610552,0.10646075,-0.043370813,1.7480745,-2.2944877,-3.1605985,-1.6391975,-7.095166,-3.7557817,5.4080186,0.10568914,4.0953684,-1.19336,-0.9421694,1.5580657,0.46144417,-12.847836,-0.56539434,-3.0693579,2.9707422,-2.531527,-1.9475306,-4.704893,-6.006575,-7.8847857,-3.6468377,5.4597855,-1.5623895,-1.797339,0.92626953,6.398387,-6.762101,1.9531705,-1.3630233,2.390186,2.5278063,3.1254492,-0.019055277,-0.7428546,2.1847603,-2.1828103,1.4034708,0.6231173,-0.2957927,-0.84363973,-0.5891937,-7.13969,-2.984557,4.2461133,-0.0047393143,3.2826393,1.8137207,0.7612394,-2.4475958,-7.6755066,-0.26007876,1.2894601,-2.1722891,0.41980484,0.33953062,0.8011271,0.6080874,1.6786568,-1.5826949,0.96929777,2.1869373,-1.4610796,0.9717245,0.37602153,-3.29317,4.2101665,-3.66834,-9.488436,-10.495393,-2.8539734,1.4567105,-1.5225351,5.230264,-4.21834,3.1522338,3.250054,-1.5318253,4.6889243,0.65156317,-5.8644433,3.2576122,2.6570964,0.10688385,6.5554404,-1.0969232,4.8560605,2.03068,3.6161659,4.0506454,0.4897484,3.6077876,2.9021409,8.987304,-5.969025,-4.8460054,-2.6618533,-6.6743665,-1.8714685,-1.528018,-1.0946128,3.191937,2.1150227,0.4240326,-0.12897238,-2.8893437,0.51120675,0.44430706,-1.0171475,1.2871358,-0.0139936805,-0.011909157,1.7586393,2.1494741,0.84941626,4.422266,0.6511395,4.7111354,-1.1762007,-2.8422682,-2.1795459,-2.8635714,0.9893013,2.421118,2.2546422,2.6234508,-0.29021508,-0.3478276,1.97315,-3.5735385,-3.6515715,0.5971906,1.1222857,1.0880299,7.203254,0.4150662,0.6335225,-0.5934408,5.575279,0.79902315,3.1195364,3.1684177,-0.17001766,-0.00007888675,-7.735902,-0.7968463,0.35266986,1.2870617,1.0453825,1.9368367,3.2792754,-4.5747924,7.64397,2.2893417,-3.9949095,-2.5405645,0.9638356,-1.0532033,5.4413886,1.9482744,-3.2530572,-2.1348834,1.858319,-7.9861717,-5.32734,-1.9072534,7.2387366,-2.27429,-1.8645507,-2.4354908,3.4778068,2.0148215,3.5544777,-1.840067,7.883061,-5.989023,-1.62221,1.353614,2.4710405,-2.9359422,-0.56465906,-0.9770415,-2.400259,-7.840347,-16.024366,0.8311968,-1.1060965,2.7434816,0.5646068,-6.4461246,-1.708587,-2.7199562,2.4495487,-4.1674967,-3.516477,-3.0913446,5.5654173,-3.6884546,-1.3634012,-6.0156007,-2.3734553,5.4079776,-2.9289732,-0.4496914,-18.759193,-0.5396146,-2.4397976,0.4095861,0.87930524,-1.1694379,-1.8521253,-0.7702347,2.4296489,2.7398052,-0.2717608,-3.7564106,8.908988,3.9067762,-0.08010268,-1.6796523,5.1209316,1.6415639,-1.0234673,-8.186377,1.3485205,2.8824642,1.4154135,-2.8709729,-1.1998055,-6.201372,5.0202813,0.5447649,-3.834599,-5.380905,-5.90541,-0.5777852,5.8581233,3.2150717,1.8781538,1.2775697,-7.933796,-1.827465,5.2612658,-6.994598,-1.6859199,-1.9420884,2.1648636,-4.871343,-2.0732496,-1.1159147,-8.415355,2.9038785,2.2203825,-0.18369466,5.794785,-0.36497372,3.7091262,1.0449505,2.994887,0.63159716,2.3687563,-1.3963798,-1.5894532,-0.0008636415,2.5169117,-3.8198333,-1.4414145,-0.5759441,4.7440886,-5.9201174,-1.4722679,-4.5171676,2.6979856,3.3305836,-7.465737,0.20017919,1.1972649,1.2112254,-6.850082,2.9427557,1.4295791,0.5411577,-7.4804473,-1.1665777,-4.1839013,0.062319905,1.3772858,-3.0309343,-1.4100568,-6.33213,2.1791074,-5.614129,5.1566877,3.585179,-2.4978151,-0.1653511,-2.1193643,-1.7009654,2.4271665,5.6256304,-3.5491295,7.0589204,-1.9224544,-0.9060893,-1.1694915,0.90015686,3.1370227,3.3282893,0.9570886,10.619905,-1.7602369,-6.68748,-4.803817,1.2377269,-1.2769606,2.4749362,-4.6399384,3.5207713,1.1565872,4.759127,-3.2965097,4.0786953,-2.7745967,1.5448526,1.4752711,-2.1909885,6.489717,-1.7363373,-0.03858739,-0.7613163,5.073901,0.047945976,-6.268509,-0.5578085,8.2434635,0.70657825,2.5162654,-6.9058156,-4.88953,-0.43947276,-5.601836,-0.9507531,-3.8826666,1.6315737,0.5361568,-2.5539913,-1.4327625,-1.8213108,-1.2174832,-0.04169172,1.5015672,-5.628986,0.9945948,1.713448,0.5545286,-2.3154018,2.0571735,-1.2428665,-2.1046042,-7.7785645,10.313141,2.5131369,-1.7810061,1.6756594,1.2006366,0.25930992,0.470982,-1.3646939,1.3542062,-1.6106118,4.3913727,3.7901018,1.558242,2.7665653,-3.2860565,1.0453719,-0.0409756,-4.201235,-5.468184,-0.9581932,-0.1539605,2.7364585,0.10076642,1.5853311,2.6398365,2.9546473,1.9021189,-2.9222417,3.6559174,0.2141082,-3.322847,-3.6706002,0.07476339,4.4796596,7.872679,-3.8440518,1.6137792,-5.570052,3.395672,3.3493457,0.13480774,0.6556939,-0.545721,1.6095566,0.8904253,-1.8484719,-0.004791498,-0.6044452,-7.1919765,1.9711483,1.467606,5.21938,-2.0558863,-0.44607618,-0.021732956,2.5669787,0.6991178,-3.095185,2.280613,5.370202,1.1787932,6.460532,4.269673,-3.6322403,-0.1218088,4.660771,-3.3349915,2.5325263,2.083195,-1.4010543,2.508265,-0.6789341,-0.3208926,-6.633943,-3.4414597,-9.757273,0.81188726,2.2301419,4.6938267,-0.3204249,1.9749966,-2.1350403,-0.59287417,-3.8271096,0.67330205,-5.762437,1.2482258,-0.27582604,0.07875234,0.57639134,11.596464,-1.2309859,-3.2709587,3.3758724,4.518855,0.5387602,0.51930606,-1.3208693,0.11863464,-0.26851025,2.648584,3.0099595,2.9920878,-0.3584968,-0.6298882,3.2744093,1.0463685],"xaxis":"x","y":[1.8583332,-2.636277,0.012316104,0.52049124,1.2070724,0.33909595,-0.11479597,-0.26815152,-0.6729688,0.0681993,-0.06413329,0.19240168,-0.56244135,1.3442318,-0.10080589,-0.10990234,0.14210734,-0.3041014,0.023766227,-0.114617825,-0.26957768,-0.11098431,-0.05006083,1.2838708,0.0689123,0.055937994,0.11755383,-0.09402943,-0.47059268,-0.29306155,0.4293577,0.020563304,0.17861778,-0.25784528,-0.08739276,-0.026736006,-0.059702814,0.22732693,-0.60545695,0.106771976,0.13207573,0.20033546,-0.16040723,0.18171413,-0.093334734,-0.044712976,-0.2518137,0.1342058,0.29238576,0.0043754727,-0.05444693,-0.796235,-0.13132171,0.5839228,-0.18524876,0.08251391,0.28944564,-0.06406322,0.08808695,0.6931729,-1.5759988,-0.096358135,0.15256587,0.15386271,0.27335832,0.092154294,-0.4219495,0.41199392,-0.21171497,0.2747431,-0.7842859,-0.11285137,-0.06590393,0.5411776,0.06465908,-0.11171122,1.1517317,0.6576679,-0.114739865,0.040900238,-0.08463596,-0.06425932,-0.011283658,0.07773675,0.23489952,0.10841814,-0.19114664,-0.40113783,-0.21188201,0.06796824,-0.0155439675,0.0020411946,0.10271963,0.0042030886,0.32234067,0.002230689,-0.06667393,0.029305568,1.4969497,0.14606632,0.003997691,-0.13386114,0.09759854,0.24302371,0.14812434,-0.1611573,0.09559256,0.012208082,0.27950692,0.0877056,-0.07192464,-0.48899305,0.2600274,-0.21098636,-0.20231722,-0.049942642,-0.18726026,0.2392477,-0.00047138706,-0.012431666,0.15487972,0.19808166,0.42917663,0.06901889,-0.083149105,0.22843254,-0.39512897,0.058741372,0.052437466,0.34035152,0.032348663,0.03760958,0.06458813,-0.23377042,0.06706742,-0.11595233,-0.06785854,0.31729865,0.02297875,-0.069675416,-0.08853133,0.013348538,1.0119392,-0.113545775,-0.03622248,0.0768437,0.06882751,0.08966348,-0.3748324,0.20277861,-0.0796306,0.022132203,-0.017292112,-0.3413338,-0.41467077,-0.33714938,0.025769368,-0.057895124,-1.3521216,-0.033290908,-0.13051909,0.08313828,-0.17471708,0.24290301,0.07930231,-0.15645388,0.4038971,0.029201858,0.11734508,0.012822665,0.11197838,0.008607987,0.14028779,0.18256249,-0.17015252,0.17671901,0.029305369,-0.027315676,-0.09998864,0.070959516,-0.15929694,0.020461246,0.29074258,0.026747083,0.036776885,0.14776263,0.15829954,-0.07825899,0.061643727,0.03002148,0.035612132,-0.07574384,0.051643595,0.0049437582,-0.027557045,0.4222288,0.25016725,0.042554446,0.053151842,-0.29057646,-0.16724303,0.12988716,0.03933331,0.02503494,0.421215,-0.08101544,0.039768644,-0.013535462,0.04385054,0.23523565,-0.19144103,0.06626902,-0.0105118975,-0.16661525,-0.008057363,0.014758863,-0.027339965,0.24923715,-0.5287517,0.2395733,-0.1771755,0.007985041,0.031019785,0.025298549,-0.052973352,0.07029711,-0.15872416,-0.11788154,-0.13632976,-0.11026019,-0.0951747,0.04406037,0.015068587,0.115747586,-0.18771054,0.05986169,0.08535257,0.12297523,-0.33377522,0.25852168,0.057153624,-0.49414617,0.10775284,-0.13173911,0.107336804,0.05859555,0.0012371615,-0.07394771,-0.5371886,-0.1351881,-0.07546462,0.13111976,-4.2835236,0.16942379,-0.0889304,-0.009028845,0.069666356,-0.03356707,0.1419267,0.15928134,-0.06190656,0.019147549,0.009757534,-0.052454747,-0.13239197,0.07519051,-0.59813327,-0.10282543,0.03434288,-0.18356958,0.05627658,-0.2513634,-0.1587777,-0.21046211,0.17217866,0.03994407,-0.039555386,0.05076623,-0.06563899,-0.14102875,-0.01091072,0.28602588,0.17535903,-0.21272291,-0.009491667,0.04355384,-0.0403772,-0.20902716,0.0027994625,-0.027683362,0.055658255,0.11408232,-0.5197147,0.24908833,0.08295852,0.021110602,0.06541479,0.17328224,0.023881957,0.00028131157,0.17036976,0.43380016,-0.107597515,-0.36848646,0.14323907,-0.14663658,0.10915314,0.083555885,0.53628695,0.043547325,0.1513896,0.029323181,-0.08149777,-0.1166842,-0.06280229,0.13113423,0.022320624,-0.06770418,-0.075480446,-0.19742827,-0.03895551,0.10670352,-0.06601073,-0.12906244,0.09944376,0.043883298,0.038000315,0.13380581,0.21860082,-0.434155,0.05700669,-0.10046288,-0.11259201,0.09172279,-0.03333336,0.09413928,0.02285014,-0.1842994,0.059489854,0.091721565,0.22954877,0.028380992,0.023528535,0.09307082,-0.073905244,0.07251886,0.07496361,0.09684825,-0.1307038,0.04447525,0.0672283,0.040981986,-0.634146,0.09357415,0.23709345,0.104995936,-0.20905305,0.13709557,-0.083075196,-0.053323925,0.3738081,0.18229288,0.09943016,0.016795088,-0.21692543,0.14019355,0.30154145,0.06552147,-0.08017604,-0.076784804,0.083587006,-0.14250334,-0.11319448,-0.04991453,0.12527436,0.0006931834,-0.0114319995,0.4545626,-0.06491069,0.16705954,-0.038045637,-0.2544961,-0.06415596,0.10409059,0.039648872,0.18676607,-0.072579324,0.033945166,0.12484613,-0.12802619,0.25670502,0.101803884,0.1164354,0.014729187,-0.30945766,0.03010312,0.27982336,0.11354038,-0.14735384,0.20012465,0.09216175,-0.3100831,-0.0398285,-0.114677325,-0.06920256,0.12897876,-0.08858642,0.16509718,0.1392145,0.05766181,-1.2587627,0.11676487,0.08044319,0.06606504,-0.09486939,-0.005222138,-0.24293573,0.18692923,-0.03464769,0.27218467,0.22213854,0.019499347,0.24468617,0.22787604,-0.009991899,-0.023703389,-0.029093802,0.08502907,0.15564221,0.102228746,0.13305798,0.07065835,0.20305799,0.06566657,-0.039134897,0.26002496,-0.11657457,0.06005668,0.029752027,-0.04961884,-0.0025348589,0.038992457,-0.02470082,0.072104834,0.1882813,0.029806256,0.06494316,-0.12760499,0.034197677,0.046407793,0.12769473,0.16273612,-0.19501929,-0.008808829,0.40056503,0.043918468,0.009801526,0.06345913,-2.195568,0.27942368,0.11299043,0.09371788,0.028459055,-0.04967972,-0.111948684,0.062397372,0.007109251,-0.24375735,0.24957536,-0.13096397,0.100974604,0.055947248,0.08816443,-0.17526579,0.29930818,-0.0917633,-0.0477546,0.04199329,-0.05107764,0.3312769,0.067014605,-0.1313111,0.0495414,-0.0029613227,0.06298964,-0.0109297335,0.073569484,-0.27762628,0.16304666,-0.09715547,-0.23126073,-0.13606231,0.18481427,-0.08398682,0.35228962,0.05392654,0.35203582,0.03745563,-0.20113091,0.085539035,0.19089793,0.036713324,-0.16736527,0.5609504,0.02055429,0.1187242,0.1567859,0.017533552,0.026933644,-0.0007853545,0.18053603,0.1544986,-0.056340978,0.08217871,-0.070032015,0.1385735,-0.53623563,0.06471574,0.080308005,-0.30711615,-0.06515155,-0.0067691617,0.06605816,-0.11532369,-0.06882435,-0.10933654,0.17270339,-0.16667506,0.048936486,-1.8951491,0.0031963177,-0.379084,0.055016745,-0.85868376,0.5572777,0.08150195,-0.16839077,0.016906016,0.092974275,0.034163386,0.08146468,0.12635812,0.06945073,0.19178607,-0.6756182,-0.058947034,0.07929717,0.08205854,-0.025064014,-1.2524803,-0.035706416,0.05215735,0.078141496,-0.007135637,-0.09728554,-0.060104847,0.020477798,0.17128886,-0.8905397,-0.19280642,0.017205589,-0.25014204,0.21836437,-0.18389264,0.024747359,0.27271163,0.0515895,0.10101752,-0.093710065,-0.13774432,0.07947324,0.049197268,0.12153868,-0.061811596,-0.6369369,0.055152275,0.025065755,0.019262917,0.029767923,-0.041107528,-0.023446135,0.1556578,0.062067147,0.14302085,0.0765488,-0.14933398,-0.1032365,-0.26409858,0.037212044,0.09172074,0.06955413,-0.003223978,-0.021445587,-0.06549884,0.21551238,0.2653141,0.038826402,-0.17494799,-0.14092876,0.15810396,-0.060298838,-0.5042797,0.27974698,-0.06976412,0.05233632,0.14509954,0.041977275,-0.03320361,0.20230953,-0.07656948,0.07774823,0.09974691,0.038872935,0.11934941,0.0022959858,-0.083755225,-0.17620872,0.052971106,-0.25882173,0.05453775,0.10154728,0.07548196,0.030939275,0.03842646,0.12506464,0.044333242,0.0047419444,-0.054952584,0.17230901,-1.3887885,0.06882417,-0.3134566,0.02085561,-0.07634841,0.090290226,-0.0758917,-0.087375075,-0.0039156117,0.047620542,-0.072778106,0.13411468,0.15196486,0.036293924,0.029164324,0.14611474,0.16592216,0.053756546,-0.12367351,0.09594172,-0.17848922,-0.63510966,0.0013345964,0.07466933,0.16573262,-0.02156867,0.042129874,0.13167107,0.021292519,-0.0037397854,0.010892693,0.12256649,0.003587313,0.07104042,0.112166926,0.14464258,0.018108636,-0.038216032,0.0057995543,0.0036129355,0.13237771,-0.37647492,0.06739305,-0.049837075,0.0036437735,-0.24057083,-0.44737244,0.13038298,0.09995608,0.064837374,-3.452231,0.0793757,0.09086044,-0.017865755,0.09075391,-0.2832318,0.037106603,0.15807635,0.026205057,0.04267316,-0.010398723,0.015893638,0.086278595,-0.21181042,0.06971528,0.17261651,0.09982194,0.06967544,-0.34091383,0.101189196,0.22676042,-0.028321676,0.09236455,-0.08799839,-0.10362242,-0.12233028,-0.029670708,-0.11927128,0.15347902,0.26828218,0.024437353,0.2350725,0.090657316,-0.1274096,-0.002917122,0.1419468,-0.088629484,-0.17514813,0.052721143,0.04172248,0.08749691,-0.05954282,-0.008434527,-0.16047814,-0.04826674,0.11535674,0.10034378,-0.23576804,0.18931358,0.040221266,0.07568913,0.024592709,0.10041206,0.113527805,0.17905086,0.09292047,0.122265354,0.08920662,-0.08353956,-0.17591672,-0.07899982,0.018590353,-0.23201977,0.06952208,0.09132551,0.018460695,-0.06226965,-0.052218296,0.049886327,0.19628385,0.08803959,0.13188371,0.06957204,0.19996159,-0.6351511,-0.028696075,-0.05787409,-0.18084326,0.101593845,0.037915356,-0.080852956,0.27667445,0.04137294,-0.018334977,0.064842306,0.32382572,0.13714194,-0.09045741,0.4204201,0.06110327,0.021075536,0.0622969,-0.12141779,-0.21494858,0.054888528,-0.026751325,0.021931548,0.10178372,0.004318133,-3.2450368,0.08944731,0.061629303,0.04338668,0.10967107,-0.18747722,-0.05693967,0.07593614,0.06500954,-0.10354896,0.10460168,-0.18780623,0.17633061,0.113791496,-0.28888232,0.048313178,-0.015821584,0.138822,-0.037192047,0.043177724,0.05594664,0.083972365,-0.40797144,-0.34291,-0.06689087,0.18198958,0.014770709,0.28809863,0.19827116,-0.038016133,0.27996606,0.071174815,0.19458152,-0.06358105,0.13824505,-0.11193998,-0.02864939,-0.31094962,0.008377325,-0.40020615,-0.087708905,0.12818049,-0.015734725,-0.0011356771,-0.00086713955,0.042196583,0.13050282,0.121570796,0.016466878,-0.009396635,0.12292849,0.08730888,-0.051054582,0.076617874,0.17429006,0.083025366,0.051515352,0.079640195,-0.032058313,0.04297079,0.012121778,-0.1344041,0.10469641,-0.050231032,0.06051796,0.6688326,-0.091093704,0.02638378,0.10974687,-0.048923045,0.1094656,0.062461313,-0.03916236,-0.0498173,0.051930625,-0.019894727,0.04182312,-0.2809474,0.10155764,0.11536418,0.24928495,0.13646068,0.11324969,-0.027513228,-0.51011413,0.07114561,0.08573981,0.07821991,0.12648058,-0.07838045,0.017383657,0.123830244,-0.6209133,-0.5091882,0.043183055,0.23607308,0.07956329,-0.06489528,0.04633548,0.22044043,-0.013201915,-0.008673631,0.10533862,-0.048644774,-0.03639161,-0.057799235,-0.52808726,-0.06029194,-0.25897163,0.0037671626,-0.17406179,0.13699648,0.047112122,0.061304435,0.092893675,0.021090262,0.045650754,0.061238453,-0.07481724,0.06511248,0.0688145,0.1063476,0.18147433,0.037999496,0.07586375,-0.024952412,0.08755128,-0.04237181,0.07196956,0.13805231,-0.05890864,-0.13467032,-0.5697384,0.00497387,0.22618239,0.062264193,-0.02919066,-0.09233825,-0.0119824335,0.13138273,0.103814304,0.10694927,-0.08482508,0.045509066,0.07520218,0.070506275,0.06444737,-0.18167777,0.032458086,-0.009100564,0.026850639,0.032006316,0.58706516,0.09324836,0.038474515,-0.12077215,0.091934934,-0.15702252,0.007943746,0.07355745,-0.13728082,0.080782026,-0.16056561,0.0019275956,0.013918791,-0.02148977,-0.15811162,0.08687173,-0.03813965,-0.09954445,-0.016568035,-0.08437449,-0.07735267,0.11719876,0.12511152,0.15158583,0.07184107,-1.4178674,-0.02960848,0.19571489,0.08130874,-0.035223626,0.15390089,-0.035463452,0.032524057,-0.24499284,-0.057361178,0.081643745,-0.030775666,0.016257793,0.023337279,0.024516981,0.073223956,0.013814192,-4.784091,-0.08391629,-0.028007291,0.0025761537,0.02119331,0.1120245,-0.05214742,-0.050258048,0.32901788,0.38685,0.011438746,-0.037047364,0.034542494,0.10954021,0.014145199,0.01915333,0.10804115,0.030554391,-0.0205978,0.106204,0.014106628,0.117887676,0.09474333,-0.021103792,0.060679767,0.068309434,0.16460958,0.21615182,0.110309884,0.18646924,0.06717181,0.19143263,0.12023969,0.040915355,0.046638247,-0.06152778,-0.08698191,-0.034109592,-0.06894815,0.10522865,0.0536499,0.0032825805,-0.59044284,-0.09152372,0.03917292,0.060294513,0.031080255,-0.013115495,0.07044694,0.13280827,0.09315419,0.08390997,0.10059042,-0.05043885,0.04780336,0.15794069,-0.016040124,0.037289456,-0.18201874,0.038552828,0.020869754,0.10268488,-0.24622504,0.08103739,0.022297863,0.22267695,-0.08532627,0.19553962,-1.639085,0.013455883,-0.21162488,0.19427727,0.1556267,0.063739926,0.24238573,-0.015932098,0.2631482,0.13051169,0.004153393,-0.27470112,-0.07281867,0.14211655,0.022678293,-0.07420637,0.109134346,0.42055738,0.09107508,0.18038362,-0.015283421,-0.04508929,-0.03956318,-0.0052466094,0.15540165,-0.094737574,0.22133783,0.0444543,0.12305802,0.12960313,-0.03394319,0.12428006,-0.002742406,-2.9923673,0.058809448,0.07479246,0.18312989,-0.08826274,0.06760522,-0.4583897,0.4448349,-0.34997392,0.052885074,0.20276283,0.05042571,0.12117871,0.046081215,0.22467953,-0.0074286982,0.101829775,0.2814023,-0.107441306,-0.027558431,-0.05868444,0.13439263,0.022150379,-0.15834303,0.027944908,0.09254953,0.35176563,0.06848869,0.07259587,0.16370498,0.18715203,0.08988921,0.17648962,0.21499749,-1.2248163,0.04077182,0.08038893,-0.1243307,0.0473124,0.16078365,0.020908713,-0.06558297,0.03904074,-0.047934674,0.36187202,0.1652636,0.08476126,0.05537769,0.008970309,0.053131282,0.04830416,0.01685531,0.18471289,0.05959823,0.0030211285,0.18591909,0.080725096,-0.26844347,0.40941888,-0.034305885,0.076939926,0.06931085,0.05498026,0.16522807,0.067950204,0.056619704,0.034158878,0.03164251,0.21791564,-0.12759352,0.08360559,-0.04075923,-0.092470765,0.07338555,-0.13793951,0.20892875,-0.10002065,-0.20912795,0.035099685,-0.028679103,0.11129566,0.05958746,0.06484453,0.07646316,0.008900229,0.11848422,-1.7250403,0.014471345,0.08950512,0.0794561,-0.05672332,0.22001606,0.0569412,0.66824496,-0.1627284,0.011884641,0.060609333,0.19032513,0.020177439,0.08371916,-0.03510879,0.06843061,-0.027199663,0.10117288,-0.027685374,0.007002458,-0.014073722,-0.0011488758,0.112205714,0.08641835,-0.05295136,0.07687753,-0.02153065,0.09615384,0.054349802,-0.41103095,-0.15446527,0.18138911,-0.09407939,0.045831863,0.15283129,-0.05421137,0.17346738,-0.3218916,0.12660572,-0.08420563,0.22580634,-0.1397903,0.023736466,0.11041187,-0.012730584,0.01999265,0.1832378,0.16533548,0.07697375,0.026852695,-0.10325478,-0.0020168573,-0.005779609,0.04911082,0.09935763,0.19325158,-0.18834634,-0.09921566,0.05897525,0.040054936,-0.024458922,-0.123495355,0.12297374,0.08121711,-0.1210344,-0.06800317,0.1582283,0.14928259,0.2500194,-0.18580246,0.0030027628,-0.14505605,-0.03797654,0.27722722,-0.070435494,-0.29523557,-0.07218048,-0.029593043,0.010227263,0.22184777,0.10306744,0.07078997,0.12852488,0.23315887,0.19503441,0.023341823,0.017833669,0.07953021,0.05727724,0.0981598,0.096051216,-0.35197848,0.15996683,0.0766154,-0.03443332,0.0194702,0.068344824,0.0055927597,0.1404133,0.09708169,0.016959839,0.05388496,0.12318272,-0.11474152,0.12084987,0.12075454,0.013261937,0.022715434,0.04136592,0.0074411966,-0.025365956,0.037161566,-0.0037478022,0.03327762,0.05236305,0.11469953,-2.725632,0.08242087,0.01650909,0.11981311,-0.107069254,0.14492124,0.27112275,-0.005826965,0.042221896,-0.0005893223,0.26039585,-0.025015913,0.0068606623,0.07914509,0.0031409413,-0.005003784,-0.42818117,-0.02904994,0.1045402,0.06970161,-0.025060683,0.69362086,0.024697274,0.027813707,0.10133961,0.057729397,0.049482524,-0.123477414,-0.17158677,0.4264714,0.16203079,-0.08585821,0.24277143,0.06467415,-0.07098244,0.10882673,0.009276424,0.07167954,0.07023212,-0.10017346,0.11057034,-0.05108607,-0.055123128,-0.025616184,0.24807271,0.102288276,-0.06035708,0.046810962,0.102472365,-0.07618266,-0.09570226,-0.036324047,0.07886481,-0.12630405,-0.028333291,0.109976366,0.09001227,-0.016050369,0.1019121,0.15805224,0.26576358,0.011864293,0.11347212,0.102076724,-0.1357071,0.15004045,0.21897052,0.083706886,-0.113753244,0.023054175,0.0059733912,0.007835198,-0.07273243,-0.0023190007,-0.15821773,-0.6884042,0.09995922,0.09597631,0.13170043,0.028652623,0.026558634,0.13381019,0.19388631,0.10491944,-0.14123407,-0.24472229,0.027759198,-0.062095538,0.082883194,0.049640395,0.00585331,0.07512284,0.038438037,0.031473033,0.7334623,-0.018620893,0.02606071,-0.17586228,0.07817776,-0.06554961,0.1595514,0.13214454,0.105850786,-0.039652385,0.014736358,-0.05764234,0.11628276,0.03410594,-0.068662554,-0.0015608519,0.098598935,0.01282651,-0.018857367,-0.060296416,0.2983145,0.4231797,-0.05203966,0.06876985,0.021948595,0.09333435,-0.051292546,-0.12062064,0.11853118,0.02495291,-2.689224,0.1315468,0.06558296,-0.11287701,0.044244863,0.107575566,0.17748085,0.06488626,0.034481667,-0.013117723,-0.017021447,-0.029273994,0.10657264,0.1806962,0.046259627,0.070064686,-0.025037326,-0.16170776,-0.04208204,0.072214864,-0.08284587,0.0072445236,-0.051360846,0.23999196,-0.005627889,0.13384116,0.07124498,0.00054914504,-0.30223197,0.040762737,0.1380714,-0.10627502,0.24517204,0.034539647,0.15054415,0.07604473,0.18378337,-0.06627957,0.0082209,0.056594197,0.31100214,0.255812,0.035164878,-0.015122227,-0.042301327,-0.15233071,0.07302153,0.09483495,0.032843076,0.11070609,0.071686365,-0.5822462,0.025914008,0.07083465,-0.05512426,0.096919805,0.061462026,0.05135048,0.0068988428,0.18275535,0.012892824,0.14145496,0.13185054,0.029828914,-0.04416097,0.17936498,-0.16005377,-0.11614147,-0.0127803385,0.07238143,0.0072139576,0.09419064,-0.12057619,0.027605388,0.036809824,0.084856555,-0.046872757,-0.35492206,-0.19604637,-0.05210752,-0.11289401,0.012117948,-0.2214096,-0.08975318,0.05645717,-0.117055535,-0.1459768,0.03654565,-0.061345994,0.15196185,0.013103813,0.0878918,0.01853107,-0.022471637,0.019413356,0.048413366,0.04094408,0.024617387,0.11522865,0.15962628,0.18297054,0.18979524,0.011198413,0.19169408,0.21361145,-0.12351984,-0.014217824,-0.014769986,-0.0727222,0.11535725,0.067216806,0.18644759,-0.07188329,0.0374156,0.14493477,0.3192736,-0.013274364,0.041945912,0.1520969,-0.082347885,-0.014844663,-0.13019048,-0.024281569,-0.018734701,0.20245054,-0.2827438,-0.057944365,-0.0040332787,0.03523373,0.20192403,0.06698114,0.07952351,0.26289707,-0.04386767,0.09851647,0.13059229,0.14753693,0.12946585,0.030023886,-0.07204144,0.036169853,0.044530407,0.0091975,0.029708419,0.042008176,0.12426018,-3.215862,-0.12808101,0.10059948,-0.022275671,0.07468839,0.07186654,-0.0048424266,0.048125036,0.08626609,0.04668215,-0.043809615,-0.04090129,0.11368267,0.008348472,-0.16423519,0.13831383,-2.0551212,-0.035330616,0.07445808,0.17428344,0.014388986,-0.0023532473,0.02246067,0.034503464,-0.016131863,0.027574321,0.0871192,-0.12540609,-0.03759881,0.10706788,0.15857296,-0.088658184,0.11187141,-0.08548015,-0.018738732,0.034007702,0.09492333,-0.084628716,0.30917138,0.08235342,0.06359918,0.0042922124,0.049439,0.08488352,0.04792743,-0.14617173,-0.010123648,0.050541077,0.03520763,0.009041745,0.24788554,0.071722046,0.20754108,0.030919597,0.079264775,0.06798001,-0.9482987,0.1392715,0.045145974,0.031079,0.04798002,0.30666697,0.14950074,-0.028669737,0.019884665,0.083684236,0.24970676,0.08055746,0.21926102,-0.015332051,-0.03186436,0.04854762,-0.10250619,-0.10867058,-0.08828314,0.037053198,-0.0021076165,-0.5654003,-0.018067896,0.008775052,0.053887725,-0.036216103,0.08674011,0.12039254,0.05673584,0.71828204,0.114052236,-0.008264065,0.25923294,0.02435596,0.28953502,0.10383369,0.21983156,0.07242882,0.119454496,0.09781106,0.10625295,-0.20342048,0.19641143,0.08553926,0.20664845,0.41044092,0.050489716,0.24167357,-0.14864492,0.15679014,-0.35090208,0.04096504,0.06442052,0.075144835,0.0048760995,-0.0759114,-0.12511057,0.07735198,0.040707782,0.0488151,0.04537642,0.038166262,0.10544985,0.0076437853,0.06679785,-0.006341677,-0.097251385,0.17674398,0.028253343,0.47430712,0.012408439,-0.022015482,-0.10820937,0.15641224,0.15691221,0.003373485,0.12195459,0.07733779,0.039554648,0.12505543,0.015965141,-0.058732703,0.008742642,0.120268896,0.026924247,0.037938684,0.18571615,0.06289983,0.008709237,0.024382293,-0.11502074,0.07647325,0.055907287,0.10280652,0.07809944,0.21279101,0.25558233,0.033134956,-0.019914806,0.15391698,0.14418459,0.050860375,-0.07002221,0.08656728,0.13393971,0.07621388,-0.16211978,0.31783557,0.055047028,0.047378168,0.003318306,-0.15912245,0.07190104,0.021902502,0.07926263,0.12342172,0.25372946,-0.16700646,0.119433835,0.08917464,-0.011367202,0.10301489,0.020016383,0.04843319,-0.24005981,0.15434624,-0.08355181,0.026641207,0.027858652,0.16519243,-0.16943559,-0.2918924,0.07993005,-0.0491309,-0.017518356,0.0044979528,0.23450045,0.050118275,0.14215499,0.11184037,0.08676455,-0.13962395,-0.6366743,-0.087216645,0.018357705,0.062334433,0.004609462,0.043369386,0.02552239,0.12353466,-0.12054835,0.17860958,-0.06880032,0.32487357,0.061578967,0.13026205,0.045957133,0.023928367,-0.034225225,-1.3589395,-0.039292812,0.087984264,-0.0010568909,0.06268538,0.11617421,0.12872264,0.5127485,-0.04113003,0.22314706,-0.038015097,-0.004031904,0.0005013682,-0.9793551,0.07612351,-0.025541939,0.1299368,-0.03769347,0.10626906,0.036609016,0.093701296,-0.034499794,-0.15605126,0.1907523,-0.0025323331,-0.015829436,0.057751205,0.020636957,0.104419574,-0.022942893,0.0019662566,0.010541562,0.20778188,0.12578693,0.04139656,0.0635228,0.018280689,0.009926464,0.12804316,0.0692182,0.023597449,-0.002358023,0.11309822,-0.10639402,0.15963952,0.051095884,-0.19358286,0.20825686,0.12156611,0.012051873,0.1516336,0.14026137,-0.0070913397,0.15399209,-0.027291112,0.06446083,0.11439668,0.05016567,0.009233307,0.07381412,-0.14786364,0.009569578,0.26135778,-0.05031076,0.11952928,0.0054054335,-0.017626926,0.06044054,0.15957054,0.112319626,-0.025015332,-0.1556992,-0.086728364,0.08260128,0.04489914,0.042352233,0.059595093,-0.5736374,0.018189568,0.0018199496,0.013814222,0.0010768771,-0.122183874,-0.0043957643,0.07566217,0.10730444,0.082930356,0.11362406,-0.42595142,0.13432574,0.016082712,0.10325004,-0.013387367,0.029372735,0.068882376,-0.094759,0.030344231,0.05358761,0.060723707,-0.047011286,0.024125304,-0.033964835,0.017058577,0.47718447,0.060851716,0.103696436,0.054431047,-0.12722917,-0.046963587,-0.051543035,-2.8089416,0.10999487,0.06048773,-0.14681369,-0.06330956,0.17213914,-0.000076022,0.07465536,0.23869789,0.031361528,0.05983249,0.017367695,-0.47019404,0.002168931,0.03703457,0.05152784,0.37208462,0.16596434,-1.2848206,-0.14942856,0.013476394,0.019867789,0.19965923,-0.064901285,0.07294212,0.10167009,0.037369575,-0.026766032,-0.31457388,-0.009848446,0.13790807,0.103774995,0.23708735,-0.0199508,0.12861474,0.024598116,-0.21943243,-0.037528343,0.07376906,-0.027937815,0.09589602,0.072504304,-0.012042925,0.05604957,0.022602633,0.07060552,0.11511029,0.05448976,-0.03384018,-0.0350276,0.037743762,0.19808775,0.13145581,0.011894103,0.07747856,-0.098577276,-0.14136334,0.0130087435,-0.009997807,0.012190338,0.04906436,0.027988985,-0.03822218,0.038740348,0.1914479,0.032014184,-0.0055969805,-0.26963556,0.011410929,-0.058543973,0.0067698397,0.16427955,0.064349875,-0.016132712,-0.047446772,0.042862136,0.021867879,0.071639195,-0.0828519,0.005955506,0.09285444,-0.29657924,-0.054329656,0.090640426,-0.030996472,0.043692444,0.071390286,0.09108408,0.09480667,0.12822649,-0.0027579926,-0.7411781,0.12414866,-0.01223994,-0.020784587,0.06272796,0.118976094,-0.33764237,0.17040995,0.016749177,-0.54665875,-0.028501652,-0.09727189,-0.024878904,0.14911842,0.022443935,0.064057715,-0.14542401,0.1193669,-0.05746074,0.07084743,-0.0050122403,0.036070563,-0.04780055,0.18975204,-0.06781967,-0.003996879,-0.04441823,0.023774985,0.049720205,0.18728404,0.00562378,0.055982374,0.08245799,0.04832872,-0.060141765,0.288439,0.017669838,0.036470823,0.07133233],"yaxis":"y","type":"scattergl"}],                        {"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmapgl":[{"type":"heatmapgl","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"}}},"xaxis":{"anchor":"y","domain":[0.0,1.0],"title":{"text":"x0"}},"yaxis":{"anchor":"x","domain":[0.0,1.0],"title":{"text":"x1"}},"legend":{"tracegroupgap":0},"title":{"text":"2D PCA of Word Embeddings"},"height":600,"width":800},                        {"responsive": true}                    ).then(function(){
                            
var gd = document.getElementById('d9471c33-c12c-4e43-894d-adda76c9b211');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };                            </script>        </div>


</div>
</div>
<p>In the graph above, the embedding of the words “Wednesday”, “Thursday”, “Monday”, “Tueday”, and “Friday” appear to be clustered together but not inside the central cluster. Moreover, their x1 values appear to be close to 0. Whereas their x0 values appear to range between -16 and -19. Since they are clustered outside of the central cluster, this means that these words likely do not help one differentiate between fake and real news.</p>
<p>Moreover, the fact that they are clustered together also makes sense, because all of them are days of the week.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>